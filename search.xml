<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>disk test</title>
    <url>/2021/03/10/disk-test/</url>
    <content><![CDATA[<p>最近看&lt;&lt;大话存储&gt;&gt;这本书，书中硬件架构部分的东西触及不到，认识不深刻，为了对于磁盘性能有接触，云上试用了两台服务器，对其性能指标进行测试。</p>
<ul>
<li>1.性能指标<br>iops，shorted for input output per sencond,每秒读写的次数<br>吞吐量，每秒磁盘写入及读出的数据量<br>时延，单个读写操作被处理的时间</li>
<li>2.性能测试工具<br>fio:该命令参数较多，可以测试随机写，随机读，混合随机读写等，写吞吐量，读吞吐量等，切记，fio写命令尽量不要在系统盘测试，会破坏文件系统，造成不可挽回的失误</li>
</ul>
<p>dd:该命令比较简单,能大致获取读写速率<br>写：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">time dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;test.file bs&#x3D;1M count&#x3D;2 oflag&#x3D;direct</span><br></pre></td></tr></table></figure>
<p>读：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">time dd if&#x3D;test.file of&#x3D;&#x2F;dev&#x2F;null  iflag&#x3D;direct</span><br></pre></td></tr></table></figure>
<ul>
<li>3.磁盘性能监控<br>top命令中的wa值用来判断磁盘IO性能<br>sar命令(yum -y install sysstat)<br>iostat命令<br>ioping磁盘IO的延迟监测工具<br>关于这些命令各指标的含义，有时间出一篇文章详细说明</li>
</ul>
]]></content>
      <tags>
        <tag>disk</tag>
        <tag>performance</tag>
      </tags>
  </entry>
  <entry>
    <title>openssl experiment</title>
    <url>/2021/03/10/openssl-experiment/</url>
    <content><![CDATA[<p>k8s中各组件与master的通讯使用http，如果apiserver需要对外提供服务，则应该使用安全系数更高的https,k8s提供基于CA签名的双向数字证书认证方式和简单基于HTTP BASE 或TOKEN的认证方式，CA证书的安全性最高，基于此，openssl的TLS证书相关理论对入门者来说是必须，本文参考《openssl-cookbook》，实践大多源于此书。</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># wget https://www.openssl.org/source/openssl-1.1.1g.tar.gz</span></span><br><span class="line"><span class="comment"># ./config \</span></span><br><span class="line">  --prefix=/opt/openssl \</span><br><span class="line">  --openssldir=/opt/openssl \</span><br><span class="line">  no-shared \</span><br><span class="line">  -DOPENSSL_TLS_SECURITY_LEVEL=2 \</span><br><span class="line">  enable-ec_nistp_64_gcc_128</span><br><span class="line"> <span class="comment"># make &amp;&amp; make install</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 生成RSA key</span></span><br><span class="line"></span><br><span class="line">``` bash</span><br><span class="line"><span class="comment"># openssl genpkey -out fd.key \</span></span><br><span class="line">  -algorithm RSA \</span><br><span class="line">  -pkeyopt rsa_keygen_bits:2048 \</span><br><span class="line">  -aes-128-cbc</span><br><span class="line">输入密码：</span><br></pre></td></tr></table></figure>

<p>查看rsa格式：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># openssl pkey -in fd.key -text -noout</span></span><br></pre></td></tr></table></figure>

<p>生成共钥匙：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># openssl pkey -in fd.key -pubout -out fd-public.key</span></span><br></pre></td></tr></table></figure>

<p>生成证书请求CSR,输入交互式的信息：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># openssl req -new -key fd.key -out fd.csr</span></span><br></pre></td></tr></table></figure>
<p>（CSR creation is usually an interactive process during which you’ll be providing the elements of the certificate distinguished name. Read the instructions given by the openssl tool careful- ly; if you want a field to be empty, you must enter a single dot (.) on the line, rather than just hit Return. If you do the latter, OpenSSL will populate the corresponding CSR field with the default value. (This behavior doesn’t make any sense when used with the default OpenSSL configuration, which is what virtually everyone does. It does make sense once you realize you can actually change the defaults, either by modifying the OpenSSL configuration or by pro- viding your own configuration files.)）<br>According to Section 5.4.1 of RFC 2985,12 challenge password is an optional field that was intended for use during certificate revocation as a way of identifying the original entity that had requested the certificate. If entered, the password will be included verbatim in the CSR and communicated to the CA. It’s rare to find a CA that relies on this field; all instructions I’ve seen recommend leaving it alone. Having a challenge password does not increase the security of the CSR in any way. Further, this field should not be confused with the key passphrase, which is a separate feature</p>
<p>检查证书请求</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># openssl req -text -in fd.csr -noout</span></span><br></pre></td></tr></table></figure>
<p>生成自签证书：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># openssl x509 -req -days 365 -in fd.csr -signkey fd.key -out fd.crt</span></span><br></pre></td></tr></table></figure>
<p>You don’t actually have to create a CSR in a separate step. The following command creates a self-signed certificate starting with a key alone:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># openssl req -new -x509 -days 365 -key fd.key -out fd.crt</span></span><br></pre></td></tr></table></figure>
<p>If you don’t wish to be asked any questions, use the -subj switch to provide the certificate<br>subject information on the command line:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># openssl req -new -x509 -days 365 -key fd.key -out fd.crt \</span></span><br><span class="line">   -subj <span class="string">&quot;/C=GB/L=London/O=Feisty Duck Ltd/CN=www.feistyduck.com&quot;</span></span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>openssl</tag>
      </tags>
  </entry>
  <entry>
    <title>pod</title>
    <url>/2021/03/10/pod/</url>
    <content><![CDATA[<p>1.如果pod中运行两个容器，这两个容器的相当于在pod上ip运行，要注意端口是否有冲突</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat pod2container.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">   name: tomcat</span><br><span class="line">   labels:</span><br><span class="line">      app: tomcat</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx:latest</span><br><span class="line">          ports:</span><br><span class="line">          - containerPort: 8080</span><br><span class="line">        - name: t2</span><br><span class="line">          image: tomcat:8.0</span><br><span class="line">          ports:</span><br><span class="line">          - containerPort: 9090</span><br><span class="line"># kuberctl get pods -o wide</span><br><span class="line"># curl http:&#x2F;&#x2F;ip:8080</span><br><span class="line"># curl http:&#x2F;&#x2F;ip:80</span><br></pre></td></tr></table></figure>
<p>2.静态pod<br>静态pod直接由某个节点上的kubelet程序进行管理，不需要api server介入，可以通过配置文件方式和http方式<br>3.pod中使用configmap的环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat conpod.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: cm-appvars</span><br><span class="line">data:</span><br><span class="line">   apploglevel: info</span><br><span class="line">   appdatadir: &#x2F;var&#x2F;data</span><br><span class="line">cat podconfig.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: cm-test-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: cm-test</span><br><span class="line">    image: tomcat:8.0</span><br><span class="line">    command: [ &quot;&#x2F;bin&#x2F;sh&quot;,&quot;-c&quot;,&quot;env | grep APP&quot; ]</span><br><span class="line">    env:</span><br><span class="line">    - name: APPLOGLEVEL</span><br><span class="line">      valueFrom:</span><br><span class="line">       configMapKeyRef:</span><br><span class="line">         name: cm-appvars</span><br><span class="line">         key: apploglevel</span><br><span class="line">    - name: APPDATADIR</span><br><span class="line">      valueFrom:</span><br><span class="line">       configMapKeyRef:</span><br><span class="line">         name: cm-appvars</span><br><span class="line">         key: appdatadir</span><br><span class="line"># kubctl logs cm-test-pod</span><br></pre></td></tr></table></figure>
<p>4.在容器内获取Pod信息(Downward API)<br>5.Pod的生命周期(RestartPolicy)<br>6.Pod健康检查-探针(LivenessProbe和ReadinessProbe)<br>7.pod亲和性反亲和性topology污点容忍<br>8.DaemonSet在每个node上调度一个Pod</p>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>openssl</tag>
      </tags>
  </entry>
  <entry>
    <title>iptables</title>
    <url>/2021/03/13/iptables/</url>
    <content><![CDATA[<p>1.禁止ping</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -t filter -I INPUT -p icmp -j REJECT</span><br><span class="line">iptables -L (默认是filter表)</span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination</span><br><span class="line">REJECT     icmp --  anywhere             anywhere             reject-with icmp-port-unreachable</span><br></pre></td></tr></table></figure>
<p>2.去除禁ping</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -t filter -D INPUT -p icmp -j REJECT</span><br></pre></td></tr></table></figure>
<p>3.禁用某一地址</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -I INPUT -s 10.211.55.2 -j </span><br><span class="line">iptables -I INPUT -s 10.211.55.0&#x2F;24 -j REJECT</span><br></pre></td></tr></table></figure>
<p>4.物理接口的设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -I INPUT -i eth0 -j DROP</span><br></pre></td></tr></table></figure>
<p>5.设置协议的某些端口应用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -I INPUT -s 10.211.55.2 -p tcp --dport 80 -j ACCEPT</span><br><span class="line">iptables -I INPUT -s 10.211.55.2 -p tcp --dport 22 -j REJECT</span><br></pre></td></tr></table></figure>
<p>6.设置TCP的某一种类型的包</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -I INPUT -i eth0 -p tcp --tcp-flags SYN,RST,ACK SYN -j DROP</span><br></pre></td></tr></table></figure>
<p>当前已经远程连接的ssh不受影响，但是重新握手会失败，连接不上<br>7.单项ping的控制</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -I INPUT -p icmp --icmp-type 8 -j DROP</span><br></pre></td></tr></table></figure>
<p>icmp请求是8，应答是0,自己可以单向ping其他机器<br>8.一次放行多个端口</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -A INPUT -p tcp -m multiport --dport 80,21,22 -j DROP</span><br></pre></td></tr></table></figure>
<p>9.多IP的设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -A INPUT -p tcp -m iprange --src-range 10.211.55.2 10.211.55.8 -j DROP</span><br></pre></td></tr></table></figure>
<p> 10.tcp连接中状态的设置<br> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -I INPUT -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPT</span><br></pre></td></tr></table></figure><br> 11.常用网络配置<br> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> IPT&#x3D;&quot;&#x2F;sbin&#x2F;iptables&quot;</span><br><span class="line">$IPT --delete-chain</span><br><span class="line">$IPT --flush</span><br><span class="line">$IPT -P INPUT DROP    #1</span><br><span class="line">$IPT -P FORWARD DROP  #1</span><br><span class="line">$IPT -P OUTPUT DROP   #1</span><br><span class="line">$IPT -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT #2</span><br><span class="line">$IPT -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT #3</span><br><span class="line">$IPT -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT #3</span><br><span class="line">$IPT -A INPUT -p tcp -m tcp --dport 21 -j ACCEPT  #3</span><br><span class="line">$IPT -A INPUT -p tcp -m tcp --dport 873 -j ACCEPT #3</span><br><span class="line">$IPT -A INPUT -i lo -j ACCEPT #4</span><br><span class="line">$IPT -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT  #5</span><br><span class="line">$IPT -A INPUT -p icmp -m icmp --icmp-type 11 -j ACCEPT #5</span><br><span class="line">$IPT -A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT #6</span><br><span class="line">$IPT -A OUTPUT -p udp -m udp --dport 53 -j ACCEPT #7</span><br><span class="line">$IPT -A OUTPUT -o lo -j ACCEPT #4</span><br><span class="line">$IPT -A OUTPUT -p tcp -m tcp --dport 80 -j ACCEPT #8</span><br><span class="line">$IPT -A OUTPUT -p tcp -m tcp --dport 25 -j ACCEPT #9</span><br><span class="line">$IPT -A OUTPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT  #10</span><br><span class="line">$IPT -A OUTPUT -p icmp -m icmp --icmp-type 11 -j ACCEPT #10</span><br><span class="line">service iptables save</span><br><span class="line">service iptables restart</span><br><span class="line">存为脚本iptables.sh，执行sh iptables.sh自动配置防火墙。</span><br><span class="line">解释：</span><br><span class="line">#1、设置INPUT,FORWARD,OUTPUT链默认target为DROP，也就是外部与服务器不能通信。</span><br><span class="line">#2、设置当连接状态为RELATED和ESTABLISHED时，允许数据进入服务器。</span><br><span class="line">#3、设置外部客户端连接服务器端口80,22,21,873。</span><br><span class="line">#4、允许内部数据循回。</span><br><span class="line">#5、允许外部ping服务器 。</span><br><span class="line">#6、设置状态为RELATED和ESTABLISHED的数据可以从服务器发送到外部。</span><br><span class="line">#7、允许服务器使用外部dns解析域名。</span><br><span class="line">#8、设置服务器连接外部服务器端口80。</span><br><span class="line">#9、允许服务器发送邮件。</span><br><span class="line">#10、允许从服务器ping外部。</span><br></pre></td></tr></table></figure><br> 脚本转自：<a href="https://www.centos.bz/2011/09/example-webserver-iptable-ruleset/">https://www.centos.bz/2011/09/example-webserver-iptable-ruleset/</a></p>
]]></content>
      <tags>
        <tag>防火墙</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>jenkins</title>
    <url>/2021/03/15/jenkins/</url>
    <content><![CDATA[<p>选择一个LTS(long time support)jenkins版本<br>夜间构建+自动化测试+度量指标<br>1.jenkins的目录结构<br> build目录存放所有构建数据，历史记录，可以迁移使用，历史数据过多可以设置Discard old buildings保留策略管理<br> jobs目录中包含配置运行的job，以xml形式显示<br>2.变量引用<br> 系统配置-&gt;全局属性中可以定义变量，在构建配置中可以使用${varname}来使用变量<br>3.调整触发构建的规则<br>  include path和exclude path匹配正则表达式，识别不该触发构建的文件，或者哪些用户的限制<br>4.各种插件<br>  构建通知邮件，即时消息，代码复杂度静态检查等<br>5.构建参数<br>  参数的设置，获取及传递，一般用于手动触发构建<br>6.多重结构的构建作业<br>  多组有效组合进行构建，节点设置标签(如数据库，操作系统)，可以设置无效的过滤器<br>7.依赖关系图<br>8.汇总测试结果<br>  需要饱含相同指纹构建的产物<br>9.分布式架构<br>  从节点的安装方式有两种，ssh，JNLP(拷贝slave.jar包，命令行启动)，正则表达式匹配可以运行的节点<br>10.监控<br>  磁盘监控disk-usage插件，计算资源监控monit插件<br>11.jenkins备份<br>  workspace目录无需备份，如果丢失会自动生成，build是构建的历史记录,backup和thinback插件都可以，定期备份策略及恢复到指定版本<br>  项目归档–手动操作<br>  jenkins的迁移<br>12.自动化测试<br>本书阅读完毕，maven使用部分没有吃透，还可以看第二遍，有时间可以参加CJE和CCJE的线上考试，价格99$,后续要读的书：<br><a href="https://github.com/PacktPublishing/Continuous-Delivery-with-Docker-and-Jenkins-Second-Edition/">https://github.com/PacktPublishing/Continuous-Delivery-with-Docker-and-Jenkins-Second-Edition/</a><br>期待有更大的收获。。。    </p>
]]></content>
      <tags>
        <tag>自动发布</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>scurity</title>
    <url>/2021/03/14/scurity/</url>
    <content><![CDATA[<p>本书讲的安全的基本理论，CIA,threat model,security level<br>1编译安装和二进制安装的区别<br>编译安装需要收集模块，花费时间，可以二次开发代码，灵活性大<br>二进制包是经过编译的代码包，安装简单，默认配置，看不到源码<br>rpm安装工具可以是安装源码，也可以安装二进制<br>2.常用安全措施<br>#a.启动用户设置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># groupadd httpd</span><br><span class="line"># useradd httpd -g httpd -d &#x2F;dev&#x2F;null -s &#x2F;sbin&#x2F;nologin</span><br></pre></td></tr></table></figure>
<p>调整httpd.conf</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">User httpd</span><br><span class="line">Group httpd</span><br></pre></td></tr></table></figure>
<p>#b.文件权限设置，80端口启动需要root权限</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># chown -R root:root &#x2F;usr&#x2F;local&#x2F;apache</span><br><span class="line"># chmod -R go-w &#x2F;usr&#x2F;local&#x2F;apache</span><br><span class="line"># chmod -R go-r &#x2F;usr&#x2F;local&#x2F;apache&#x2F;conf </span><br><span class="line"># chmod -R go-r &#x2F;usr&#x2F;local&#x2F;apache&#x2F;logs</span><br></pre></td></tr></table></figure>
<p>#c.文件权限设置，非任何文件都可见,配置httpd.conf</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Directory &#x2F;&gt;</span><br><span class="line">    Order Deny,Allow</span><br><span class="line">    Deny from all</span><br><span class="line">&lt;&#x2F;Directory&gt;</span><br><span class="line">&lt;Directory &#x2F;var&#x2F;www&#x2F;htdocs&gt;</span><br><span class="line">    Order Allow,Deny</span><br><span class="line">    Allow from all</span><br><span class="line">&lt;&#x2F;Directory&gt;</span><br></pre></td></tr></table></figure>
<p>#d.禁用符号连接，使用Alias</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Options -FollowSymLinks</span><br><span class="line">Alias &#x2F;manual&#x2F; &#x2F;usr&#x2F;local&#x2F;apache&#x2F;manual&#x2F;</span><br></pre></td></tr></table></figure>
<p>或者要使用符号连接，推荐开启用户检测功能</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Options -FollowSymLinks +SymLinksIfOwnerMatch</span><br></pre></td></tr></table></figure>
<p>#e.收回服务端脚本执行权限</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Options -Includes -ExecCGI</span><br></pre></td></tr></table></figure>
<p>#f.特定的目录执行脚背</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Directory &#x2F;var&#x2F;www&#x2F;cgi-bin&gt;</span><br><span class="line">    Options ExecCGI</span><br><span class="line">    SetHandler cgi-script</span><br><span class="line">&lt;&#x2F;Directory&gt;</span><br></pre></td></tr></table></figure>
<p>3.日志<br> First, use the LogFormat directive to define a logging format. Then, use the CustomLog directive to create an access log in that format:<br> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined</span><br><span class="line">CustomLog &#x2F;var&#x2F;www&#x2F;logs&#x2F;access_log combined</span><br></pre></td></tr></table></figure><br>4.配置限制</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># wait up to 300 seconds for slow clients</span><br><span class="line"> TimeOut 60</span><br><span class="line"> # allow connections to be reused between requests</span><br><span class="line"> KeepAlive On</span><br><span class="line"> # allow a maximum of 100 requests per connection</span><br><span class="line"> MaxKeepAliveRequests 100</span><br><span class="line"> # wait up to 15 seconds for the next</span><br><span class="line"> # request on an open connection</span><br><span class="line"> KeepAliveTimeout 15</span><br></pre></td></tr></table></figure>
<p>请求的限制</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># impose no limits on the request body</span><br><span class="line"> LimitRequestBody 0</span><br><span class="line"> # allow up to 100 headers in a request</span><br><span class="line"> LimitRequestFields 100</span><br><span class="line"> # each header may be up to 8190 bytes long</span><br><span class="line"> LimitRequestFieldsize 8190</span><br><span class="line"> # the first line of the request can be</span><br><span class="line"> # up to 8190 bytes long</span><br><span class="line"> LimitRequestLine 8190</span><br><span class="line"> # limit the XML request body to 1 million bytes(Apache 2.x only)</span><br><span class="line"> LimitXMLRequestBody 1000000</span><br></pre></td></tr></table></figure>
<p>服务端实例的限制</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># keep 5 servers ready to handle requests</span><br><span class="line">MinSpareServers 5</span><br><span class="line"># do not keep more than 10 servers idle</span><br><span class="line">MaxSpareServers 10</span><br><span class="line"># start with 5 servers</span><br><span class="line">StartServers 5</span><br><span class="line"># allow a max of 150 clients at any given time</span><br><span class="line">MaxClients 150</span><br><span class="line"># allow unlimited requests per server</span><br><span class="line">MaxRequestsPerChild 0</span><br></pre></td></tr></table></figure>
<p>Apache 2 introduces the concept of multiprocessing modules (MPMs), which are special-pur- pose modules that determine how request processing is organized. Only one MPM can be ac- tive at any one time. MPMs were introduced to allow processing to be optimized for each op- erating system individually. The Apache 1 processing model (multiple processes, no threads, each process handling one request at one time) is called prefork, and it is the default process- ing model in Apache 2 running on Unix platforms. On Windows, Apache always runs as a single process with multiple execution threads, and the MPM for that is known as winnt. On Unix systems running Apache 2, it is possible to use the worker MPM, which is a hybrid, as it supports many processes each with many threads. For the worker MPM, the configuration is similar to the following (refer to the documentation for the complete description):<br>在进程–线程MPM模型上控制</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># the maximum number of processes</span><br><span class="line">ServerLimit 16</span><br><span class="line"># how many processes to start with</span><br><span class="line">StartServers 2</span><br><span class="line"># how many threads per process to create</span><br><span class="line">ThreadsPerChild 25</span><br><span class="line"># minimum spare threads across all processes</span><br><span class="line">MinSpareThreads 25</span><br><span class="line"># maximum spare threads across all processes</span><br><span class="line">MaxSpareThreads 75</span><br><span class="line"># maximum clients at any given time</span><br><span class="line">MaxClients 150</span><br></pre></td></tr></table></figure>
<p>5.关闭正则匹配</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;FilesMatch &quot;(^\.ht|~$|\.bak$|\.BAK$)&quot;&gt;</span><br><span class="line">    Order Allow,Deny</span><br><span class="line">    Deny from all</span><br><span class="line">&lt;&#x2F;FilesMatch&gt;</span><br></pre></td></tr></table></figure>
<p>6.修改服务头<br>源码中修改core.c文件，编译后文件修改ap_release.h，还可以通过第三方模块mod_security添加配置修改，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Reveal full identity (standard Apache directive)</span><br><span class="line">ServerTokens Full</span><br><span class="line"># Replace the server name (mod_security directive)</span><br><span class="line">SecServerSignature &quot;Microsoft-IIS&#x2F;5.0&quot;</span><br></pre></td></tr></table></figure>
<p>apache2模块mod_headers修改头信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Header set Server &quot;Microsoft-IIS&#x2F;5.0&quot;</span><br></pre></td></tr></table></figure>
<p>这种修改方式对于异常请求不生效，如状态吗400<br>7.chroot的使用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;chroot</span><br><span class="line">mkdir &#x2F;chroot&#x2F;bin</span><br><span class="line">cp &#x2F;bin&#x2F;bash &#x2F;chroot&#x2F;bin&#x2F;bash</span><br><span class="line">chroot &#x2F;chroot &#x2F;bin&#x2F;bash</span><br><span class="line">ldd &#x2F;bin&#x2F;bash  #查看依赖</span><br><span class="line"># mkdir &#x2F;chroot&#x2F;lib</span><br><span class="line"># cp &#x2F;lib&#x2F;libtermcap.so.2 &#x2F;chroot&#x2F;lib </span><br><span class="line"># cp &#x2F;lib&#x2F;libdl.so.2 &#x2F;chroot&#x2F;lib</span><br><span class="line"># cp &#x2F;lib&#x2F;tls&#x2F;libc.so.6 &#x2F;chroot&#x2F;lib </span><br><span class="line"># cp &#x2F;lib&#x2F;ld-linux.so.2 &#x2F;chroot&#x2F;lib</span><br><span class="line">chroot &#x2F;chroot &#x2F;bin&#x2F;bash</span><br><span class="line"># mkdir -p &#x2F;chroot&#x2F;apache&#x2F;usr&#x2F;local</span><br><span class="line"># mv &#x2F;usr&#x2F;local&#x2F;apache &#x2F;chroot&#x2F;apache&#x2F;usr&#x2F;local</span><br><span class="line"># ln -s &#x2F;chroot&#x2F;apache&#x2F;usr&#x2F;local&#x2F;apache &#x2F;usr&#x2F;local&#x2F;apache </span><br><span class="line"># mkdir -p &#x2F;chroot&#x2F;apache&#x2F;var</span><br><span class="line"># mv &#x2F;var&#x2F;www &#x2F;chroot&#x2F;apache&#x2F;var&#x2F;</span><br><span class="line"># ln -s &#x2F;chroot&#x2F;apache&#x2F;var&#x2F;www &#x2F;var&#x2F;www</span><br><span class="line"># ldd &#x2F;chroot&#x2F;apache&#x2F;usr&#x2F;local&#x2F;apache&#x2F;bin&#x2F;httpd</span><br><span class="line"># mkdir &#x2F;chroot&#x2F;apache&#x2F;lib</span><br><span class="line"># cp &#x2F;lib&#x2F;tls&#x2F;libm.so.6 &#x2F;chroot&#x2F;apache&#x2F;lib</span><br><span class="line"># cp &#x2F;lib&#x2F;libcrypt.so.1 &#x2F;chroot&#x2F;apache&#x2F;lib</span><br><span class="line"># cp &#x2F;usr&#x2F;lib&#x2F;libgdbm.so.2 &#x2F;chroot&#x2F;apache&#x2F;lib # cp &#x2F;usr&#x2F;lib&#x2F;libexpat.so.0 &#x2F;chroot&#x2F;apache&#x2F;lib # cp &#x2F;lib&#x2F;libdl.so.2 &#x2F;chroot&#x2F;apache&#x2F;lib</span><br><span class="line"># cp &#x2F;lib&#x2F;tls&#x2F;libc.so.6 &#x2F;chroot&#x2F;apache&#x2F;lib</span><br><span class="line"># cp &#x2F;lib&#x2F;ld-linux.so.2 &#x2F;chroot&#x2F;apache&#x2F;lib</span><br><span class="line"># mkdir &#x2F;chroot&#x2F;apache&#x2F;etc</span><br><span class="line"># cp &#x2F;etc&#x2F;nsswitch.conf &#x2F;chroot&#x2F;apache&#x2F;etc&#x2F;</span><br><span class="line"># cp &#x2F;lib&#x2F;libnss_files.so.2 &#x2F;chroot&#x2F;apache&#x2F;lib</span><br><span class="line"># echo &quot;httpd:x:500:500:Apache:&#x2F;:&#x2F;sbin&#x2F;nologin&quot; &gt; &#x2F;chroot&#x2F;apache&#x2F;etc&#x2F;passwd </span><br><span class="line"># echo &quot;httpd:x:500:&quot; &gt; &#x2F;chroot&#x2F;apache&#x2F;etc&#x2F;group</span><br><span class="line"># cp &#x2F;lib&#x2F;libnss_dns.so.2 &#x2F;chroot&#x2F;apache&#x2F;lib </span><br><span class="line"># cp &#x2F;etc&#x2F;hosts &#x2F;chroot&#x2F;apache&#x2F;etc</span><br><span class="line"># cp &#x2F;etc&#x2F;resolv.conf &#x2F;chroot&#x2F;apache&#x2F;etc</span><br><span class="line"># mkdir &#x2F;chroot&#x2F;apache&#x2F;dev</span><br><span class="line"># mknod -m 666 &#x2F;chroot&#x2F;apache&#x2F;dev&#x2F;null c 1 3 </span><br><span class="line"># mknod -m 666 &#x2F;chroot&#x2F;apache&#x2F;dev&#x2F;zero c 1 5 </span><br><span class="line"># mknod -m 644 &#x2F;chroot&#x2F;apache&#x2F;dev&#x2F;random c 1 8</span><br><span class="line"># mkdir &#x2F;chroot&#x2F;apache&#x2F;tmp</span><br><span class="line"># chmod +t &#x2F;chroot&#x2F;apache&#x2F;tmp </span><br><span class="line"># chmod 777 &#x2F;chroot&#x2F;apache&#x2F;tmp</span><br><span class="line"># cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;MET &#x2F;chroot&#x2F;apache&#x2F;etc&#x2F;localtime </span><br><span class="line"># mkdir -p &#x2F;chroot&#x2F;apache&#x2F;usr&#x2F;lib&#x2F;locale</span><br><span class="line"># set | grep LANG</span><br><span class="line">LANG&#x3D;en_US.UTF-8</span><br><span class="line">LANGVAR&#x3D;en_US.UTF-8</span><br><span class="line"># cp -dpR &#x2F;usr&#x2F;lib&#x2F;locale&#x2F;en_US.utf8 &#x2F;chroot&#x2F;apache&#x2F;usr&#x2F;lib&#x2F;locale</span><br></pre></td></tr></table></figure>
<p>接下来实操，to_page 67</p>
]]></content>
      <tags>
        <tag>openssl</tag>
        <tag>网络</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title>operation-making</title>
    <url>/2021/03/19/operation-making/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>operation</tag>
        <tag>thread</tag>
        <tag>process</tag>
      </tags>
  </entry>
  <entry>
    <title>docker</title>
    <url>/2021/03/22/docker/</url>
    <content><![CDATA[<p>1.断言,泛型,虚函数回顾<br> 断言一般用于程序入参检查，可提高代码阅读性，泛型是抽象参数类型，减少重复代码。<br> 虚函数意在运行时决定调用哪一个具体函数实现，纯虚函数在基类中不定义实现，virtual void func()=0<br> 而虚函数在基类中有定义实现<br>2.namespaced的介绍</p>
<ul>
<li>UTS namespace<br> UTS namespace主要用来隔离nodename和domainname两个系统标识符，每个namespace允许有自己的hostname，新的UTS namespace中更改主机名不影响宿主机 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line">import (</span><br><span class="line">&quot;os&#x2F;exec&quot;</span><br><span class="line">&quot;syscall&quot;</span><br><span class="line">&quot;os&quot;</span><br><span class="line">&quot;log&quot;</span><br><span class="line">)</span><br><span class="line">func main() &#123;</span><br><span class="line"> cmd:&#x3D;exec.Command(&quot;sh&quot;)</span><br><span class="line"> cmd.SysProcAttr&#x3D;&amp;syscall.SysProcAttr&#123;</span><br><span class="line">        Cloneflags:syscall.CLONE_NEWUTS,</span><br><span class="line">&#125;</span><br><span class="line">cmd.Stdin&#x3D;os.Stdin</span><br><span class="line">cmd.Stdout&#x3D;os.Stdout</span><br><span class="line">cmd.Stderr&#x3D;os.Stderr</span><br><span class="line">if err:&#x3D;cmd.Run();</span><br><span class="line">err!&#x3D;nil&#123;</span><br><span class="line">log.Fatal(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>IPC Namespace<br>IPC Namespace用来隔离System V IPC和POSIX message queu(进程间通信用的，后面再出详细的专题来探究)<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  package main</span><br><span class="line">import (</span><br><span class="line">&quot;os&#x2F;exec&quot;</span><br><span class="line">&quot;syscall&quot;</span><br><span class="line">&quot;os&quot;</span><br><span class="line">&quot;log&quot;</span><br><span class="line">)</span><br><span class="line">func main() &#123;</span><br><span class="line"> cmd:&#x3D;exec.Command(&quot;sh&quot;)</span><br><span class="line"> cmd.SysProcAttr&#x3D;&amp;syscall.SysProcAttr&#123;</span><br><span class="line">        Cloneflags:syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC,</span><br><span class="line">&#125;</span><br><span class="line">cmd.Stdin&#x3D;os.Stdin</span><br><span class="line">cmd.Stdout&#x3D;os.Stdout</span><br><span class="line">cmd.Stderr&#x3D;os.Stderr</span><br><span class="line">if err:&#x3D;cmd.Run();err!&#x3D;nil&#123;</span><br><span class="line">log.Fatal(err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>PID Namespace<br>PID Namespace 是用来隔离进程ID的，同养一个进程在不同的PID Namespace里可以拥有不同的PID<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line">import (</span><br><span class="line">&quot;os&#x2F;exec&quot;</span><br><span class="line">&quot;syscall&quot;</span><br><span class="line">&quot;os&quot;</span><br><span class="line">&quot;log&quot;</span><br><span class="line">)</span><br><span class="line">func main() &#123;</span><br><span class="line"> cmd:&#x3D;exec.Command(&quot;sh&quot;)</span><br><span class="line"> cmd.SysProcAttr&#x3D;&amp;syscall.SysProcAttr&#123;</span><br><span class="line">        Cloneflags:syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID,</span><br><span class="line">&#125;</span><br><span class="line">cmd.Stdin&#x3D;os.Stdin</span><br><span class="line">cmd.Stdout&#x3D;os.Stdout</span><br><span class="line">cmd.Stderr&#x3D;os.Stderr</span><br><span class="line">if err:&#x3D;cmd.Run();err!&#x3D;nil&#123;</span><br><span class="line">log.Fatal(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Mount Namespace<br>Mount Namespace用来隔离各个进程看到的挂载点视图，不同的Namespace进程中看到的文件系统层次不一样。是linux实现的第一个Namespace,系统调用参数是NEWNS,当时人们并没有意识到，以后还有很多累的Namespace加入linux大家庭<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line">import (</span><br><span class="line">&quot;os&#x2F;exec&quot;</span><br><span class="line">&quot;syscall&quot;</span><br><span class="line">&quot;os&quot;</span><br><span class="line">&quot;log&quot;</span><br><span class="line">)</span><br><span class="line">func main() &#123;</span><br><span class="line"> cmd:&#x3D;exec.Command(&quot;sh&quot;)</span><br><span class="line"> cmd.SysProcAttr&#x3D;&amp;syscall.SysProcAttr&#123;</span><br><span class="line">        Cloneflags:syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS,</span><br><span class="line">&#125;</span><br><span class="line">cmd.Stdin&#x3D;os.Stdin</span><br><span class="line">cmd.Stdout&#x3D;os.Stdout</span><br><span class="line">cmd.Stderr&#x3D;os.Stderr</span><br><span class="line">if err:&#x3D;cmd.Run();err!&#x3D;nil&#123;</span><br><span class="line">log.Fatal(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
mount -t proc proc /proc  #挂载之后查看进程</li>
<li>User Namespace<br> 用来隔离用户组ID的，一个非root用户运行创建一个User Namespace可在里面映射成root用户</li>
<li>Network Namespace<br> 用来隔离网络设备,IP地址端口等资源的</li>
</ul>
<p>3.Cgroups的介绍<br>  Cgroup提供了一组进车过将子进程的资源限制控制和统计的能力，这些资源包括CPU,内存，存储，网络等。<br>  docker中限制内存使用 docker -m 128m xxxx<br> <figure class="highlight plain"><figcaption><span>main</span></figcaption><table><tr><td class="code"><pre><span class="line">import (</span><br><span class="line">&quot;os&#x2F;exec&quot;</span><br><span class="line">&quot;path&quot;</span><br><span class="line">&quot;fmt&quot;</span><br><span class="line">&quot;io&#x2F;ioutil&quot;</span><br><span class="line">&quot;syscall&quot;</span><br><span class="line">&quot;os&quot;</span><br><span class="line">&quot;strconv&quot;</span><br><span class="line">)</span><br><span class="line">const cgroupMemoryHierarchyMount&#x3D;&quot;&#x2F;sys&#x2F;fs&#x2F;cgoup&#x2F;memory&quot;</span><br><span class="line">func main() &#123;</span><br><span class="line">    if os.Args[0]&#x3D;&#x3D;&quot;&#x2F;proc&#x2F;self&#x2F;exe&quot; &#123;</span><br><span class="line">      fmt.Printf(&quot;current pid %d&quot;,syscall.Getpid())</span><br><span class="line">      fmt.Println()</span><br><span class="line">      cmd:&#x3D;exec.Command(&quot;sh&quot;,&quot;-c&quot;,&#96;stress --vm-bytes 50m --vm-keep -m 1&#96;)</span><br><span class="line">      cmd.SysProcAttr&#x3D;&amp;syscall.SysProcAttr&#123;</span><br><span class="line">        &#125;</span><br><span class="line">      cmd.Stdin&#x3D;os.Stdin</span><br><span class="line">      cmd.Stdout&#x3D;os.Stdout</span><br><span class="line">      cmd.Stderr&#x3D;os.Stderr</span><br><span class="line">      if err:&#x3D;cmd.Run();err!&#x3D;nil&#123;</span><br><span class="line">      fmt.Println(err)</span><br><span class="line">      os.Exit(1)</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   cmd:&#x3D;exec.Command(&quot;&#x2F;proc&#x2F;self&#x2F;exe&quot;)</span><br><span class="line">   cmd.SysProcAttr&#x3D;&amp;syscall.SysProcAttr&#123;</span><br><span class="line">      Cloneflags:syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS,</span><br><span class="line">   &#125;</span><br><span class="line">      cmd.Stdin&#x3D;os.Stdin</span><br><span class="line">      cmd.Stdout&#x3D;os.Stdout</span><br><span class="line">      cmd.Stderr&#x3D;os.Stderr</span><br><span class="line">      if err:&#x3D;cmd.Start();err!&#x3D;nil&#123;</span><br><span class="line">       fmt.Println(&quot;ERROR&quot;,err)</span><br><span class="line">       os.Exit(1)</span><br><span class="line">&#125; else &#123;</span><br><span class="line">     fmt.Printf(&quot;%v&quot;,cmd.Process.Pid)</span><br><span class="line">     os.Mkdir(path.Join(cgroupMemoryHierarchyMount,&quot;testmemorylimit&quot;),0755)</span><br><span class="line">     ioutil.WriteFile(path.Join(cgroupMemoryHierarchyMount,&quot;testmemorylimit&quot;,&quot;tasks&quot;),[]byte(strconv.Itoa(cmd.Process.Pid)),0644)</span><br><span class="line">     ioutil.WriteFile(path.Join(cgroupMemoryHierarchyMount,&quot;testmemorylimit&quot;,&quot;memory.limit_in_bytes&quot;),[]byte(&quot;100m&quot;),0644)</span><br><span class="line">     &#125;</span><br><span class="line">cmd.Process.Wait()</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><br> 4.Union File System<br> 其用到的重要的资源管理技术叫“写时复制”，也叫”隐式共享“，AUFS完全重写早期的UnionFS 1.x，使用CoW技术，其主要目的是为了可靠性和性能，并且引入新的功能，比如可写的分支负载均衡，docker利用AUFS存储image和container<br> 启动一个container的时候，docker会为其创建一个read-only的init layer,用来存储与这个容器内环境相关的内容，Docker还会为其创建一个read-write的layer来执行所有的写操作。如果要删除文件file1，AUFS会在container的read-write层生成一个.wh.file1的文件来隐藏所有的read-only层的file1文件。<br>5.虚拟网络<br>  linux上虚拟网络(有时间专题研究)</p>
<p>该书代码部分实践还没动手，还需要再啃一遍，不了解的词汇还要再咀嚼</p>
]]></content>
      <tags>
        <tag>docker</tag>
        <tag>cgroup</tag>
        <tag>namespace</tag>
      </tags>
  </entry>
  <entry>
    <title>ELK</title>
    <url>/2021/03/24/ELK/</url>
    <content><![CDATA[<p>1.基本概念<br>logstash可以当作一个input|decode|filter|encode|output的数据流</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">netstat -plnu | awk &#39;NR&#x3D;1 || $4~&#x2F;:44062$&#x2F;&#123;print $2&#125;&#39;</span><br></pre></td></tr></table></figure>
<p>grok正则表达式<br>倒排索引：拆词之后建立索引,关键词,ids<br>lucene就是一个jar包，里面包含封装好的建立的倒排索引，以及进行搜索的代码<br>elastic特点：分布式，搜索，数据分析<br>全文检索/结构化检索<br>对海量数据进行近实时的处理<br>document：一条数据，包含多个field<br>index:对应于数据库<br>type：对应一张表<br>shard:index拆分为多个shard,分散到多台服务器上面，便于吞吐量横向扩展<br>replica: replica shard,副本，宕机高可用的，数据不丢失<br>数据库存储无法反映面向对象的优越性<br>es是面向文档的，使用json格式，嵌套比较方便<br>-检查集群状态</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET _cat&#x2F;health?v</span><br></pre></td></tr></table></figure>
<p>yellow状态是指primary shard活跃，replica shard非活跃状态，replica shard与primary不在同一个节点<br>查看索引：GET _cat/indices?v<br>创建索引：PUT /test_index?pretty<br>删除索引：DELETE /test_index?pretty</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;ecommerce&#x2F;product&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">    &quot;name&quot; : &quot;gaolujie yagao&quot;,</span><br><span class="line">    &quot;desc&quot; :  &quot;gaoxiao meibai&quot;,</span><br><span class="line">    &quot;price&quot; :  30,</span><br><span class="line">    &quot;producer&quot; :      &quot;gaolujie producer&quot;,</span><br><span class="line">    &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot; ]</span><br><span class="line">&#125;</span><br><span class="line">PUT &#x2F;ecommerce&#x2F;product&#x2F;2</span><br><span class="line">&#123;</span><br><span class="line">    &quot;name&quot; : &quot;jiajieshi yagao&quot;,</span><br><span class="line">    &quot;desc&quot; :  &quot;youxiao fangzhu&quot;,</span><br><span class="line">    &quot;price&quot; :  25,</span><br><span class="line">    &quot;producer&quot; :      &quot;jiajieshi producer&quot;,</span><br><span class="line">    &quot;tags&quot;: [ &quot;fangzhu&quot; ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT &#x2F;ecommerce&#x2F;product&#x2F;3</span><br><span class="line">&#123;</span><br><span class="line">    &quot;name&quot; : &quot;zhonghua yagao&quot;,</span><br><span class="line">    &quot;desc&quot; :  &quot;caoben zhiwu&quot;,</span><br><span class="line">    &quot;price&quot; :  40,</span><br><span class="line">    &quot;producer&quot; :      &quot;zhonghua producer&quot;,</span><br><span class="line">    &quot;tags&quot;: [ &quot;qingxin&quot; ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>修改商品,替换文档</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;ecommerce&#x2F;product&#x2F;1</span><br><span class="line">&#123;</span><br><span class="line">    &quot;name&quot; : &quot;jiaqiangban gaolujie yagao&quot;,</span><br><span class="line">    &quot;desc&quot; :  &quot;gaoxiao meibai&quot;,</span><br><span class="line">    &quot;price&quot; :  30,</span><br><span class="line">    &quot;producer&quot; :      &quot;gaolujie producer&quot;,</span><br><span class="line">    &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot; ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>修改商品,更新文档</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST &#x2F;ecommerce&#x2F;product&#x2F;1&#x2F;_update</span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;jiaqiangban gaolujie yagao&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2.搜索方式</p>
<ul>
<li>query string search</li>
<li>query DSL</li>
<li>query filter</li>
<li>full-text search</li>
<li>phrase search<br>全文搜索：GET /ecommerce/product/_search<br>排序搜索：GET /ecommerce/product/_search?q=name:yagao&amp;sort=price:desc<br>DSL：domain special language<br>查询所有的商品：<br>GET /ecommerce/product/_search<br>{<br>“query”:{<br>  “match_all”: {}<br>}<br>}<br>查询包含yaogao的商品，并且按照价格降序排列<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;ecommerce&#x2F;product&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;:&#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;name&quot;:&quot;yagao&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;sort&quot;:[&#123;&quot;price&quot;:&quot;desc&quot;&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
分页查询商品<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;ecommerce&#x2F;product&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;:&#123;</span><br><span class="line">    &quot;match_all&quot;: &#123;</span><br><span class="line">    &#125;&#125;,</span><br><span class="line">    &quot;from&quot;:1,</span><br><span class="line">    &quot;size&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
指定要查询的商品的名称和价格<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;ecommerce&#x2F;product&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;:&#123;</span><br><span class="line">    &quot;match_all&quot;: &#123;</span><br><span class="line">    &#125;&#125;,</span><br><span class="line">    &quot;_source&quot;:[&quot;name&quot;,&quot;price&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
查询过滤条件<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;ecommerce&#x2F;product&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;match&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &quot;yagao&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;range&quot;: &#123;</span><br><span class="line">          &quot;price&quot;: &#123;</span><br><span class="line">            &quot;gte&quot;: 25</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
全文检索，倒排索引，字段拆开，匹配分数不一样,按照匹配分数排序<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;ecommerce&#x2F;product&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;:&#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;producer&quot;: &quot;yagao producer&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
phrase search 短语搜索<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;ecommerce&#x2F;product&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;match_phrase&quot; : &#123;</span><br><span class="line">            &quot;producer&quot; : &quot;yagao producer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
高亮搜索，被标色<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;ecommerce&#x2F;product&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;match_phrase&quot; : &#123;</span><br><span class="line">            &quot;producer&quot; : &quot;yagao producer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;highlight&quot;: &#123;</span><br><span class="line">      &quot;fields&quot;: &#123;</span><br><span class="line">        &quot;producer&quot;: &#123;&#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>3.聚合<br>将文本fielddata属性设置为true</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;ecommerce&#x2F;product&#x2F;_mapping</span><br><span class="line">&#123;</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;tags&quot;:&#123;</span><br><span class="line">      &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">      &quot;fielddata&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>搜索yagao的商品，计算每个tag的数量<br>先分组，再算每组的平均值，计算每个tag下的商品的平均价格<br>然后降序排序<br>按照指定的价格范围进行分组，然后在每组内再按照tag进行分组，再计算平均价格<br>4.primary shard和replica shard的关系</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;test_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;number_of_shards&quot;: 3,</span><br><span class="line">    &quot;number_of_replicas&quot;: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>手动指定document id，从其他系统中导入一些数据到es时，会采取这种方式，作为document中的id,put<br>自动生成document id,post,分布式系统并行生成时不可能发生冲突,长度是20，GUID<br>定制返回结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GEt &#x2F;test_index&#x2F;test_type&#x2F;4?_source&#x3D;test_content2,test_content</span><br></pre></td></tr></table></figure>
<p>document的删除不会立刻删除，会先进行标记，等到物理空间不足时，再后台物理删除<br>5.并发冲突的问题,悲观锁，乐观锁<br>悲观锁常用于关系型数据库中，只有一个线程可以获得数据锁，其他线程阻塞<br>es使用的是乐观锁，每个线程可以操作，版本号来判断，更新时版本号不一致会重新读最新的版本号，优点是支持并发<br>删除一个document和再添加一个document,version版本号都会加一<br>es还可以自定义版本号，external version，不使用es自带的version号。<br>es _version=1,?version=1才能更新成功<br>es _version=1,?version&gt;1 &amp;version_type=external 才能成功<br>6.partial update的理解<br>执行流程，get请求获取document,供用户查看和修改，put请求全量替换，后台原数据标记为deleted<br>partial使用post,每次传递少量需要修改的field即可，内部实现基本一致，老的document标记为deleted<br>patail_update内置的乐观锁并发控制，retry_on_conflict,_version<br>7.批量查询<br>_mget做批量查询，发一次请求</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;_mget</span><br><span class="line">&#123;&quot;docs&quot;:[</span><br><span class="line">  &#123;&quot;_index&quot;:&quot;test_index&quot;,</span><br><span class="line">    &quot;_type&quot;:&quot;test_type&quot;,</span><br><span class="line">    &quot;_id&quot;:1</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;_index&quot;:&quot;test_index&quot;,</span><br><span class="line">    &quot;_type&quot;:&quot;test_type&quot;,</span><br><span class="line">    &quot;_id&quot;:2</span><br><span class="line">  &#125;</span><br><span class="line">  ]</span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同一index下的不同type，或者同一type下的不同id,可以简化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;test_index&#x2F;_mget</span><br><span class="line">&#123;&quot;docs&quot;:[</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;_type&quot;:&quot;test_type&quot;,</span><br><span class="line">    &quot;_id&quot;:1</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    </span><br><span class="line">    &quot;_type&quot;:&quot;test_type&quot;,</span><br><span class="line">    &quot;_id&quot;:2</span><br><span class="line">  &#125;</span><br><span class="line">  ]</span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>8.批量的增删改</p>
]]></content>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>logstash</tag>
        <tag>kibana</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP-IP</title>
    <url>/2021/04/02/TCP-IP/</url>
    <content><![CDATA[<p>1.通过tcpdump抓包分析curl <a href="http://www.baidu.com:80的数据包,http的建立连接过程">www.baidu.com:80的数据包,http的建立连接过程</a><br>11:35:05.429067 IP 10.211.55.12.33006 &gt; 180.101.49.12.80: Flags [S], seq 3061668192, win 64240, options [mss 1460,sackOK,TS val 3826981171 ecr 0,nop,wscale 7], length 0<br>客户端发送的，长度为0，SYN标识，win窗口大小，seq=3061668192</p>
<p>11:35:05.463682 IP 180.101.49.12.80 &gt; 10.211.55.12.33006: Flags [S.], seq 983544434, ack 3061668193, win 32768, options [mss 1460,wscale 1,nop], length 0<br>服务端回复的，长度为0,flag S.表示对SYN的回复,窗口大小，ack=seq+1</p>
<p>11:35:05.463790 IP 10.211.55.12.33006 &gt; 180.101.49.12.80: Flags [.], ack 1, win 502, length 0<br>客户端的回复，flag .表示客户端的回复，ack=1</p>
<p>11:35:05.463953 IP 10.211.55.12.33006 &gt; 180.101.49.12.80: Flags [P.], seq 1:78, ack 1, win 502, length 77: HTTP: GET / HTTP/1.1<br>客户端的请求，P.标示报文段，length长度为77</p>
<p>11:35:05.464137 IP 180.101.49.12.80 &gt; 10.211.55.12.33006: Flags [.], ack 78, win 16384, length 0<br>服务端的回复，长度为0</p>
<p>11:35:05.487614 IP 180.101.49.12.80 &gt; 10.211.55.12.33006: Flags [P.], seq 1:1441, ack 78, win 16384, length 1440: HTTP: HTTP/1.1 200 OK<br>服务端的回复，报文段，长度为1440</p>
<p>11:35:05.487701 IP 10.211.55.12.33006 &gt; 180.101.49.12.80: Flags [.], ack 1441, win 501, length 0<br>客户端的回复，数据报文已被接收</p>
<p>11:35:05.487745 IP 180.101.49.12.80 &gt; 10.211.55.12.33006: Flags [P.], seq 1441:2782, ack 78, win 16384, length 1341: HTTP<br>服务端的回复，报文段</p>
<p>11:35:05.487759 IP 10.211.55.12.33006 &gt; 180.101.49.12.80: Flags [.], ack 2782, win 496, length 0<br>客户端的回应，报文段被接收</p>
<p>11:35:05.487950 IP 10.211.55.12.33006 &gt; 180.101.49.12.80: Flags [F.], seq 78, ack 2782, win 501, length 0<br>四次挥手的，客户端断开链接，flag为FIN</p>
<p>11:35:05.488018 IP 180.101.49.12.80 &gt; 10.211.55.12.33006: Flags [.], ack 79, win 16384, length 0<br>服务端的响应回复，已经接受到断开链接</p>
<p>11:35:05.502739 IP 180.101.49.12.80 &gt; 10.211.55.12.33006: Flags [F.], seq 2782, ack 79, win 16384, length 0<br>服务端发送断开请求</p>
<p>11:35:05.502783 IP 10.211.55.12.33006 &gt; 180.101.49.12.80: Flags [.], ack 2783, win 501, length 0<br>客户方回复，长度为0</p>
<p>2.https的数据连接建立过程，<br> tcpdump -nn -i enp0s5 port 443<br>  curl <a href="https://woer.going-link.com/">https://woer.going-link.com</a></p>
<p>11:52:33.010061 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [S], seq 492861349, win 64240, options [mss 1460,sackOK,TS val 4055158253 ecr 0,nop,wscale 7], length 0</p>
<p>11:52:33.031735 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [S.], seq 1925487038, ack 492861350, win 32768, options [mss 1460,wscale 1,nop], length 0<br>11:52:33.031816 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 1, win 502, length 0<br>11:52:33.073490 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [P.], seq 1:244, ack 1, win 502, length 243<br>11:52:33.073640 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [.], ack 244, win 16384, length 0<br>11:52:33.100122 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 1:1461, ack 244, win 16384, length 1460<br>11:52:33.100206 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 1461, win 501, length 0<br>11:52:33.100234 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 1461:2921, ack 244, win 16384, length 1460<br>11:52:33.100245 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 2921, win 496, length 0<br>11:52:33.100247 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 2921:3352, ack 244, win 16384, length 431<br>11:52:33.100254 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 3352, win 493, length 0<br>11:52:33.101919 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [P.], seq 244:319, ack 3352, win 501, length 75<br>11:52:33.102136 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [.], ack 319, win 16384, length 0<br>11:52:33.102156 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [P.], seq 319:370, ack 3352, win 501, length 51<br>11:52:33.102225 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [.], ack 370, win 16384, length 0<br>11:52:33.134399 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 3352:3610, ack 370, win 16384, length 258<br>11:52:33.135154 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [P.], seq 370:482, ack 3610, win 501, length 112<br>11:52:33.135254 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [.], ack 482, win 16384, length 0<br>11:52:33.189986 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 3610:5062, ack 482, win 16384, length 1452<br>11:52:33.190065 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 5062:6522, ack 482, win 16384, length 1460<br>11:52:33.190080 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 6522:7966, ack 482, win 16384, length 1444<br>11:52:33.190105 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 7966:9426, ack 482, win 16384, length 1460<br>11:52:33.190110 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 9426:10870, ack 482, win 16384, length 1444<br>11:52:33.190138 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 10870, win 474, length 0<br>11:52:33.190158 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 10870:12322, ack 482, win 16384, length 1452<br>11:52:33.208657 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 12322:13782, ack 482, win 16384, length 1460<br>11:52:33.208693 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 13782, win 501, length 0<br>11:52:33.208720 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 13782:15242, ack 482, win 16384, length 1460<br>11:52:33.208727 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 15242:16678, ack 482, win 16384, length 1436<br>11:52:33.208816 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 16678:18138, ack 482, win 16384, length 1460<br>11:52:33.208825 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 18138:19582, ack 482, win 16384, length 1444<br>11:52:33.208836 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 16678, win 501, length 0<br>11:52:33.209051 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 19582:21034, ack 482, win 16384, length 1452<br>11:52:33.230570 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 21034:22486, ack 482, win 16384, length 1452<br>11:52:33.230602 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 22486, win 501, length 0<br>11:52:33.230635 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 22486:23938, ack 482, win 16384, length 1452<br>11:52:33.230685 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 23938:25390, ack 482, win 16384, length 1452<br>11:52:33.230764 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 25390, win 501, length 0<br>11:52:33.238111 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 25390:26850, ack 482, win 16384, length 1460<br>11:52:33.238134 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 26850:28310, ack 482, win 16384, length 1460<br>11:52:33.238138 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 28310:29770, ack 482, win 16384, length 1460<br>11:52:33.238140 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 29770:31230, ack 482, win 16384, length 1460<br>11:52:33.238142 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 31230:32650, ack 482, win 16384, length 1420<br>11:52:33.238214 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 32650, win 501, length 0<br>11:52:33.243072 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 32650:34102, ack 482, win 16384, length 1452<br>11:52:33.250939 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [P.], seq 34102:35025, ack 482, win 16384, length 923<br>11:52:33.250971 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 35025, win 501, length 0<br>11:52:33.253102 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [P.], seq 482:513, ack 35025, win 501, length 31<br>11:52:33.253238 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [.], ack 513, win 16384, length 0<br>11:52:33.259519 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [F.], seq 513, ack 35025, win 501, length 0<br>11:52:33.259724 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [.], ack 514, win 16384, length 0<br>11:52:33.271454 IP 122.112.210.87.443 &gt; 10.211.55.12.33520: Flags [F.], seq 35025, ack 514, win 16384, length 0<br>11:52:33.271479 IP 10.211.55.12.33520 &gt; 122.112.210.87.443: Flags [.], ack 35026, win 501, length 0</p>
<p>3.nginx做四层代理和七层代理的数据转发过程抓包分析</p>
]]></content>
      <tags>
        <tag>network</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title>docker-network</title>
    <url>/2021/04/16/docker-network/</url>
    <content><![CDATA[<p>1.实践准备<br>三台主机：<br>192.168.71.128 node01<br>192.168.71.129 node02<br>192.168.71.130 node03</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># wget https:&#x2F;&#x2F;releases.hashicorp.com&#x2F;consul&#x2F;1.9.4&#x2F;consul_1.9.4_linux_amd64.zip</span><br><span class="line"># unzip consul_1.9.4_linux_amd64.zip</span><br><span class="line"># mv consul &#x2F;usr&#x2F;local&#x2F;bin</span><br></pre></td></tr></table></figure>
<p>三台机器对修改consul配置文件consul_config_json,并修改server_name</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat consul_config.json</span><br><span class="line">&#123;</span><br><span class="line">&quot;advertise_addr&quot;:&quot;192.168.71.129&quot;,</span><br><span class="line">&quot;bind_addr&quot;:&quot;192.168.71.129&quot;,</span><br><span class="line">&quot;data_dir&quot;:&quot;&#x2F;temp&#x2F;consul&quot;,</span><br><span class="line">&quot;server&quot;:true,</span><br><span class="line">&quot;node_name&quot;:&quot;server2&quot;,</span><br><span class="line">&quot;enable_syslog&quot;:true,</span><br><span class="line">&quot;enable_debug&quot;:true,</span><br><span class="line">&quot;log_level&quot;:&quot;info&quot;,</span><br><span class="line">&quot;bootstrap_expect&quot;:3,</span><br><span class="line">&quot;start_join&quot;:[&quot;192.168.71.128&quot;,&quot;192.168.71.129&quot;,&quot;192.168.71.130&quot;],</span><br><span class="line">&quot;retry_join&quot;:[&quot;192.168.71.128&quot;,&quot;192.168.71.129&quot;,&quot;192.168.71.130&quot;],</span><br><span class="line">&quot;ui&quot;:true,</span><br><span class="line">&quot;client_addr&quot;:&quot;0.0.0.0&quot;,</span><br><span class="line">&quot;datacenter&quot;:&quot;consulnet&quot;</span><br><span class="line">&#125;</span><br><span class="line"># consul agent -config-dir &#x2F;tmp&#x2F;consul_config   &#x2F;&#x2F;start  ctrl+z bg 后台运行</span><br><span class="line"># consul operator raft list-peers &#x2F;&#x2F;查看节点状态</span><br></pre></td></tr></table></figure>
<p>由于配置文件打开了UI，consul的状态可以浏览器中查看，localhost:8500<br>2.创建网络<br>实验采用overlay网络跨主机互联</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># docker network create --driver overlay consulnet</span><br><span class="line"># docker network ls</span><br><span class="line"># docker run -it -d --name test_net1 --network consulnet1 busybox</span><br></pre></td></tr></table></figure>
<p>依次在node02，node03上创建容器test_net2，test_net3<br>还可以指定子网：</p>
<h1 id="docker-network-create-–driver-overlay-–subnet-10-20-20-0-24-cosulnet1"><a href="#docker-network-create-–driver-overlay-–subnet-10-20-20-0-24-cosulnet1" class="headerlink" title="docker network create –driver overlay –subnet 10.20.20.0/24 cosulnet1"></a>docker network create –driver overlay –subnet 10.20.20.0/24 cosulnet1</h1><p>进入各容器，互相ping容器名，可以通</p>
<h1 id="ping-test-net2"><a href="#ping-test-net2" class="headerlink" title="ping test_net2"></a>ping test_net2</h1><p>3.原理深入<br>为支持容器跨主机通信, Docker 提供了 overlay driver , 使用户可以创建基于VxLAN的overlay网络.VxLAN 可以将二层数据封装到UDP进行传输, VxLAN 提供与 VLAN 相同的以太网二层服务, 但是拥有更强的扩展性和灵活性.overlay网络 需要一个key-value 数据库用于保存网络状态信息, 包括 Network, Endpoint, IP 等,consul, etcd, zookeeper 都是docker支持的 key-value 软件,从Docker1.12开始，Docker使用内部的Key-Value存储去创建Swarm和overlay网络.<br>Virtual Extensible LAN (VXLAN) is a network virtualization technology that attempts to improve the scalability problems associated with large cloud computing deployments.<br>VXLAN是一项通道技术，它将L2（链路层）的网络帧包装在UDP包里面并通过4789端口发送出去，这项技术最开始是被VMWare，Arista和思科一起开发的。VXLAN的主要目标是简化需要在L2层多租户的云部署。它提供：</p>
<ul>
<li>通过在L3上构建通道传输L2以避免群集中所有主机之间的L2连接的必要性</li>
<li>可以超过4096个独立的网络（VLAN ID的数量被限制为不能大于4096）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@kube-master ~]# docker exec test_net1 ip addr show</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1&#x2F;128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">13: eth0@if14: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1450 qdisc noqueue</span><br><span class="line">    link&#x2F;ether 02:42:0a:14:14:02 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.20.20.2&#x2F;24 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::42:aff:fe14:1402&#x2F;64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">15: eth1@if16: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue</span><br><span class="line">    link&#x2F;ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.18.0.3&#x2F;16 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::42:acff:fe12:3&#x2F;64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@kube-master ~]# docker exec test_net1 ip route show</span><br><span class="line">default via 172.18.0.1 dev eth1</span><br><span class="line">10.20.20.0&#x2F;24 dev eth0 scope link  src 10.20.20.2</span><br><span class="line">172.18.0.0&#x2F;16 dev eth1 scope link  src 172.18.0.3</span><br></pre></td></tr></table></figure>
<p>容器中访问外部走桥接网卡，10网段之间访问走overlay网卡<br>使用tcpdump验证vxlan的通信过程,在test_net2中ping 10.10.20.2,node01上tcpdump抓包，tcpdump -pni eth0 “port 4789”</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">21:05:35.715854 IP 192.168.71.129.49297 &gt; 192.168.71.128.4789: VXLAN, flags [I] (0x08), vni 257</span><br><span class="line">IP 10.20.20.3 &gt; 10.20.20.2: ICMP echo request, id 4352, seq 0, length 64</span><br><span class="line">21:05:35.716389 IP 192.168.71.128.58844 &gt; 192.168.71.129.4789: VXLAN, flags [I] (0x08), vni 257</span><br><span class="line">IP 10.20.20.2 &gt; 10.20.20.3: ICMP echo reply, id 4352, seq 0, length 64</span><br></pre></td></tr></table></figure>
<p>每个包都产生两行信息：<br>外层帧，IP地址为192.168.71.129 和 192.168.71.128（docker宿主机）<br>里层帧，IP地址为10.20.20.3 和 10.20.20.2(我们的容器)<br>继续看看overlay层是如何将ip映射为mac地址的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">overns&#x3D;&#x2F;var&#x2F;run&#x2F;docker&#x2F;netns&#x2F;1-c2f5929a52</span><br><span class="line">nsenter --net&#x3D;$overns tcpdump -pni any &quot;arp&quot;</span><br></pre></td></tr></table></figure>
<p>test_net4容器新建时没有arp列表,ip neigh show，ping 10.10.20.2，node01宿主机抓包，没有任何arp的包信息<br>node03上重新创建干净的arp列表的test_net4，node03上抓包，nsenter –net=/var/run/docker/netns/1-1b450d1a91 tcpdump -peni any “arp”</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">21:47:50.839200   B 02:42:0a:14:14:05 ethertype ARP (0x0806), length 44: Request who-has 10.20.20.3 tell 10.20.20.5, length 28</span><br><span class="line">21:47:50.839272 Out 02:42:0a:14:14:05 ethertype ARP (0x0806), length 44: Request who-has 10.20.20.3 tell 10.20.20.5, length 28</span><br><span class="line">21:47:50.839280 Out 02:42:0a:14:14:05 ethertype ARP (0x0806), length 44: Request who-has 10.20.20.3 tell 10.20.20.5, length 28</span><br><span class="line">21:47:50.839288   B 02:42:0a:14:14:05 ethertype ARP (0x0806), length 44: Request who-has 10.20.20.3 tell 10.20.20.5, length 28</span><br><span class="line">21:47:50.839304  In 02:42:0a:14:14:03 ethertype ARP (0x0806), length 44: Reply 10.20.20.3 is-at 02:42:0a:14:14:03, length 28</span><br><span class="line">21:47:50.839338 Out 02:42:0a:14:14:03 ethertype ARP (0x0806), length 44: Reply 10.20.20.3 is-at 02:42:0a:14:14:03, length 28</span><br></pre></td></tr></table></figure>
<p>[root@kube-node3 ~]# nsenter –net=/var/run/docker/netns/1-1b450d1a91  ip neigh show<br>10.20.20.3 dev vxlan1 lladdr 02:42:0a:14:14:03 PERMANENT<br>10.20.20.2 dev vxlan1 lladdr 02:42:0a:14:14:02 PERMANENT<br>继续创建一个test_net6容器，查看ip neigh 信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@kube-node1 ~]#  nsenter --net&#x3D;&#x2F;var&#x2F;run&#x2F;docker&#x2F;netns&#x2F;1-1b450d1a91  ip neigh show</span><br><span class="line">10.20.20.4 dev vxlan1 lladdr 02:42:0a:14:14:04 PERMANENT</span><br><span class="line">10.20.20.5 dev vxlan1 lladdr 02:42:0a:14:14:05 PERMANENT</span><br><span class="line">10.20.20.2 dev vxlan1 lladdr 02:42:0a:14:14:02 PERMANENT</span><br><span class="line">10.20.20.6 dev vxlan1 lladdr 02:42:0a:14:14:06 PERMANENT</span><br></pre></td></tr></table></figure>
<p>记录被自动添加了，即使目前还没有通信包被发到这个新的容器中。这意味着Docker自动操作在overlay网络命名空间中的ARP记录，并且vxlan网卡充当一个代理去应答ARP请求。<br>查看vxlan1 网卡配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@kube-node1 ~]# nsenter --net&#x3D;&#x2F;var&#x2F;run&#x2F;docker&#x2F;netns&#x2F;1-1b450d1a91 ip -d link show vxlan1</span><br><span class="line">12: vxlan1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master br0 state UNKNOWN mode DEFAULT</span><br><span class="line">    link&#x2F;ether 22:47:5c:db:e3:cc brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 1</span><br><span class="line">    vxlan id 257 srcport 0 0 dstport 4789 proxy l2miss l3miss ageing 300</span><br><span class="line">    bridge_slave state forwarding priority 32 cost 100 hairpin off guard off root_block off fastleave off learning on flood on port_id 0x8001 port_no 0x1 designated_port 32769 designated_cost 0 designated_bridge 8000.22:47:5c:db:e3:cc designated_root 8000.22:47:5c:db:e3:cc hold_timer    0.00 message_age_timer    0.00 forward_delay_timer    0.00 topology_change_ack 0 config_pending 0 proxy_arp off proxy_arp_wifi off mcast_router 1 mcast_fast_leave off mcast_flood on addrgenmode eui64</span><br></pre></td></tr></table></figure>
<p>MAC地址的获取会是怎样的，查看overlay命名空间里的网桥转发数据库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@kube-node1 ~]# nsenter --net&#x3D;&#x2F;var&#x2F;run&#x2F;docker&#x2F;netns&#x2F;1-1b450d1a91 bridge fdb show</span><br><span class="line">33:33:00:00:00:01 dev br0 self permanent</span><br><span class="line">01:00:5e:00:00:01 dev br0 self permanent</span><br><span class="line">33:33:ff:9c:6f:3d dev br0 self permanent</span><br><span class="line">22:47:5c:db:e3:cc dev vxlan1 master br0 permanent</span><br><span class="line">22:47:5c:db:e3:cc dev vxlan1 vlan 1 master br0 permanent</span><br><span class="line">02:42:0a:14:14:02 dev vxlan1 dst 192.168.71.128 link-netnsid 0 self permanent</span><br><span class="line">02:42:0a:14:14:04 dev vxlan1 dst 192.168.71.130 link-netnsid 0 self permanent</span><br><span class="line">02:42:0a:14:14:05 dev vxlan1 dst 192.168.71.130 link-netnsid 0 self permanent</span><br><span class="line">02:42:0a:14:14:06 dev vxlan1 dst 192.168.71.130 link-netnsid 0 self permanent</span><br><span class="line">52:7a:ed:06:a3:95 dev veth2 master br0 permanent</span><br><span class="line">52:7a:ed:06:a3:95 dev veth2 vlan 1 master br0 permanent</span><br><span class="line">33:33:00:00:00:01 dev veth2 self permanent</span><br><span class="line">01:00:5e:00:00:01 dev veth2 self permanent</span><br><span class="line">33:33:ff:06:a3:95 dev veth2 self permanent</span><br></pre></td></tr></table></figure>
<p>我们可以看到docker0容器的MAC地址在数据库里面，并且被标志为permanent。这个信息也是docker动态添加的。<br>接下来查看consul中记录的信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@kube-node1 ~]# net&#x3D;$(docker network inspect cosulnet1  -f &#123;&#123;.Id&#125;&#125;)</span><br><span class="line">curl -s http:&#x2F;&#x2F;localhost:8500&#x2F;v1&#x2F;kv&#x2F;docker&#x2F;network&#x2F;v1.0&#x2F;network&#x2F;$&#123;net&#125;&#x2F; | jq  -r &quot;.[0].Value&quot;  |  base64 -d | jq .</span><br></pre></td></tr></table></figure>
<p>后续实验：<a href="https://www.jianshu.com/p/a2b94bc9c232">https://www.jianshu.com/p/a2b94bc9c232</a><br>本文参考：<br><a href="https://www.jianshu.com/p/a2b94bc9c232">https://www.jianshu.com/p/a2b94bc9c232</a></p>
]]></content>
      <tags>
        <tag>docker</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>high-performance-mysql</title>
    <url>/2021/03/31/high-performance-mysql/</url>
    <content><![CDATA[<p>1.性能的数据监控<br>常用的工具(percona toolkit):<br>pt-quiry-digest<br>oprofile<br>pt-pmp<br>数据库中的表：<br>show profiles<br>show status<br>show global status<br>2.不同键值存储的对比<br>3.索引<br>联合索引采用最左匹配原则<br>失效的情况：不能跳过索引中的列<br>如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引优化查找<br>哈希索引的查找过程：先计算键值的hash值，将hash值按照顺序存储，查找key值时，先计算其hash值，再到顺序hash中查找获得对应行的指针<br>hash索引不是按照索引的顺序存储的，所以无法用于排序<br>hash索引也不支持部分索引列匹配查找，在(A,B)上建立hash索引，如果查询只有数据A列，无法使用索引<br>hash只支持等值比较查询<br>三星系统：<br>    索引将相关的记录放到一起获得一星<br>    索引中的数据顺序和查找中的顺序一致获得二星<br>    索引中的列包含了查询中需要的全部列，获得三星<br>失效的索引:索引列不能是表达式的一部分，也不能是函数的参数<br>要始终将索引列单独放在比较符号的一侧<br>前缀索引：不能做order by和group by<br>松散索引:<br>a.查询针对一个单表。<br>b.GROUP BY包括索引的第1个连续部分(如果对于GROUP BY，查询有一个DISTINCT子句，则所有DISTINCT的属性指向索引开头)。<br>c.只使用累积函数(如果有)MIN()和MAX()，并且它们均指向相同的列。<br>d.索引的任何其它部分（除了那些来自查询中引用的GROUP BY）必须为常数(也就是说，必须按常量数量来引用它们)，但MIN()或MAX() 函数的参数例外。<br>4.复制如何工作<br>a.在主库上把数据更改记录到二进制日志里，<br>b.备库将主库上的日志复制到自己的中继日志(relay log)中<br>c.备库读取中继日志中的事件，将其重放到备库数据之上<br>4.基础<br>数据库必须支持ACID,atomicity,consistency,isolation,durability<br>a.原子性–不可分割的最小工作单元<br>b.一致性–从一个完整的状态转移到另一个完整的一致性状态，不会有中间状态<br>c.隔离性–一个事物在所做的修改最终提交以前，对其他事物是不可见的<br>d.持久性–一旦事物提交，其所做的修改就会永久的保存到数据库中    </p>
]]></content>
      <tags>
        <tag>performance</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>index-optimization</title>
    <url>/2021/04/12/index-optimization/</url>
    <content><![CDATA[<p>1.设计索引的步骤<br>a.找到索引不合适而导致运行慢的查询语句<br>b.设计索引，使所有的查询语句都运行得足够快</p>
]]></content>
      <tags>
        <tag>index</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>interview</title>
    <url>/2021/03/31/interview/</url>
    <content><![CDATA[<p>1.这两条语句的索引应该怎么建立？<br>select * from A where A.a=? order by A.b<br>Select a,max(b) from A where A.a=? Group by A.b<br>对此自己来实验，说明紧凑索引和疏松索引</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ALTER TABLE A2 ADD INDEX index1 (word, similar) ;</span><br><span class="line"></span><br><span class="line">EXPLAIN select * from A2 A where A.word&#x3D;&#39;niggle&#39; order by A.similar</span><br><span class="line"></span><br><span class="line">1	SIMPLE	A		ref	index1	index1	123	const	1	100	Using where; Using index</span><br></pre></td></tr></table></figure>
<p>对比表</p>
<p>```<br>ALTER TABLE A3 ADD INDEX index1 (similar,word) ;</p>
<p>EXPLAIN select * from A3 A where A.word=’bunch’ order by A.similar;</p>
<p>1    SIMPLE    A        index        index1    246        100    10    Using where; Using index</p>
<p>紧凑索引有一个where定位<br>松散索引:<br>a.查询针对一个单表。<br>b.GROUP BY包括索引的第1个连续部分(如果对于GROUP BY，查询有一个DISTINCT子句，则所有DISTINCT的属性指向索引开头)。<br>c.只使用累积函数(如果有)MIN()和MAX()，并且它们均指向相同的列。<br>d.索引的任何其它部分（除了那些来自查询中引用的GROUP BY）必须为常数(也就是说，必须按常量数量来引用它们)，但MIN()或MAX() 函数的参数例外。</p>
<p>explain Select max(word),similar from A3 A where A.word=’bunch’ Group by A.similar;<br>1    SIMPLE    A        range    index1    index1    246        3    100    Using where; Using index for group-by</p>
<p>Using index for group-by表明使用的是松散索引</p>
]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>工作推动</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s-network</title>
    <url>/2021/04/15/k8s-network/</url>
    <content><![CDATA[<p>K8s四层网络抽象<br>Pod网络原理</p>
<ul>
<li>同一节点上的pod网络</li>
<li>不同节点上的Pod网络<br>CNI简介</li>
</ul>
<hr>
<p>k8s的service和ingress<br>1.service的类型：<br>clusterIP：默认值，k8s系统给service自动分配虚拟IP,只能在集群内部访问<br>NodePort:将service通过指定的Node上的端口暴露给外部，访问任意一个NodeIP，nodeport都将路由到clusterIP<br>LoadBalancer:在NodePort的基础上，借助cloudprovider创建一个外部的负载均衡器，并将请求转发到NodeIP:NodePort,此模式只能在云服务器上使用<br>ExternalName:将服务通过DNS CNAME转发到指定的域名（通过spec.externalName设定）</p>
]]></content>
      <tags>
        <tag>kubernetes</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>Go-language</title>
    <url>/2021/03/26/Go-language/</url>
    <content><![CDATA[<p>1.概论<br>Go直击java和c++开发的痛点，线程间通信及内存管理，使用goroutin和通道技术简化开发，有时间可以写个http服务端，做性能压力测试<br>扩展概念：必包-内部函数对外部函数作用域里变量的引用,必包函数私有化了变量，完成了数据的封装，大规模使用对内存有损耗</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def func(): #外部函数</span><br><span class="line">	a&#x3D;1</span><br><span class="line">	print(&quot;this is func&quot;)</span><br><span class="line">	def func1(num):#内部函数</span><br><span class="line">		print(&quot;this is func1&quot;)</span><br><span class="line">		print(num+1)</span><br><span class="line">	return func1   #返回函数集装箱，对象函数名等</span><br><span class="line">var&#x3D;func()</span><br><span class="line">var(3)</span><br></pre></td></tr></table></figure>
<p>另一个概念：装饰器-执行func之前先执行装饰器函数，不影响原有函数的功能，还能添加新功能</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def func2(func):&#x2F;&#x2F;外部闭包函数参数</span><br><span class="line">	def func3():</span><br><span class="line">		print(&#39;aaabbb&#39;)</span><br><span class="line">		return func() &#x2F;&#x2F;返回函数调用，执行之后的结构</span><br><span class="line">	return func3</span><br><span class="line"></span><br><span class="line">@func2</span><br><span class="line">def myprint():</span><br><span class="line">	print(&quot;lalala&quot;)</span><br><span class="line"></span><br><span class="line">myprint()</span><br></pre></td></tr></table></figure>
<p>2.Go的一些特性<br>Go的基础部分实现得不错:有垃圾回收、包系统、-等公民函数、词法作用域、系统调用接口,还有默认用UTF-8编码的不可变字符串。但相对来说，它的语言特性不多，而且不太会增加新特性了。比如，它没有隐式数值类型强制转换，没有构造或析构函数,没有运算符重载，没有形参默认值，没有继承，没有泛型，没有异常，没有宏，没有函数注解，没有线程局部存储。这门语言成熟而且稳定，并且保证兼容更早版本:在旧版本的Go语言中写的程序，可以在新版本的编译器和标准库下编译与运行。<br>3.slice<br>for _,arg:=range os.Args[1:]{…}<br>每次迭代，range产生一对值：range 产生一对值:索引和这个索引处元素的值。这个例子里，我们不需要索引，但是语法上range循环需要处理，因此也必须处理索引。一个主意是我们将索引赋予一个临时变量(如temp)然后忽略它，但是Go不允许存在无用的临时变量，不然会出现编译错误。<br>4.main函数也运行在goroutine中<br>当一个goroutine试图在一个通道上进行发送或接收操作时，它会阻塞，直到另一个goroutine试图进行接收或发送操作才传递值，并开始处理两个goroutine。本例中，每fetch在通道ch上发送一个值(ch &lt;- expression), main 函数接收它们( &lt;-ch)。由main来处理所有的输出确保了每个goroutine作为一个整体单元处理，这样就避免了两个goroutine同时完成造成输出交织所带来的风险。<br>5.生存空间<br>如果一个实体在函数中声明，它只在函数局部有效。如果声明在函数外，它将对包里面的所有源文件可见。实体第-一个字母的大小写决定其可见性是否跨包。如果名称以大写字母的开头，它是导出的，意味着它对包外是可见和可访问的，可以被自己包之外的其他程序所引用，像fmt包中的Printf。包名本身总是由小写字母组成。<br>6.len长度的细节<br>尽管Go具备无符号整型数和相关算术运算，也尽管某些量值不可能为负，但是我们往<br>往还采用有符号整型数，如数组的长度(即便直观上明显更应该选用uint)。下例从后向前<br>输出奖牌名称，循环里用到了内置的len函数，它返回有符号整数:<br>medals := []string{“gold”, “silver”, “bronze” }<br>fori:=len(medals)-1;i&gt;=0;i–{<br>fmt . Println(medals[i]) // “bronze”, “silver”, “gold”<br>}<br>相反，假若len返回的结果是无符号整数，就会导致严重错误，因为i随之也成为uint<br>型，根据定义，条件i&gt;=0将恒成立。第3轮迭代后，有i==0，语句i–使得i变为uint型<br>的最大值(例如，可能为264-1)，而非-1，导致medals[i]试图越界访问元素，超出slice<br>范围，引发运行失败或宕机</p>
]]></content>
      <tags>
        <tag>go</tag>
        <tag>high performance</tag>
      </tags>
  </entry>
  <entry>
    <title>calico</title>
    <url>/2021/04/18/calico/</url>
    <content><![CDATA[<p>概论<br>calico创建BGB网络在docker节点中通信</p>
]]></content>
      <tags>
        <tag>network</tag>
        <tag>calico</tag>
      </tags>
  </entry>
  <entry>
    <title>https-cipher</title>
    <url>/2021/04/22/https-cipher/</url>
    <content><![CDATA[<p>1.认识<br>密码学传播的越广泛，经过曝光测试可靠性就越高，与传统的思想，加密算法需要保密才安全相违背，由此促成了密码学的发展<br>序列密码采用异或来处理，不能使用第二次，http请求时协议版本请求头可以预见，被解析出来后容易攻破其他密文，所以要隐藏请求头，请求版本</p>
]]></content>
      <tags>
        <tag>network</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title>flannel</title>
    <url>/2021/04/17/flannel/</url>
    <content><![CDATA[<p>1.基本原理<br>docker中的网卡veth0通过网桥连接主机，主机上运行flannel,flannel从etcd中获取信息，实现互联<br>node01:192.168.71.128<br>node02:192.168.71.129<br>daemon.json是用于创建使用overlay网络的，本次不涉及<br>flannel的key-value信息存储在etcd中，<br>etcdctl mk /atomic.io/network/config ‘{“Network”:”10.10.0.0/16”,”SubnetMin”:”10.10.10.0”,”SubnetMax”:”10.10.50.0”,”Backend”:{“Type”:”vxlan”}}’<br>2.etcd的基本配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat &#x2F;etc&#x2F;etcd&#x2F;etcd.conf | grep -v &quot;^#&quot;</span><br><span class="line">ETCD_DATA_DIR&#x3D;&quot;&#x2F;var&#x2F;lib&#x2F;etcd&#x2F;default.etcd&quot;</span><br><span class="line">ETCD_LISTEN_PEER_URLS&#x3D;&quot;http:&#x2F;&#x2F;192.168.71.128:2380&quot;</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS&#x3D;&quot;http:&#x2F;&#x2F;192.168.71.128:2379,http:&#x2F;&#x2F;127.0.0.1:2379&quot;</span><br><span class="line">ETCD_NAME&#x3D;&quot;node1&quot;</span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS&#x3D;&quot;http:&#x2F;&#x2F;192.168.71.128:2380&quot;</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS&#x3D;&quot;http:&#x2F;&#x2F;192.168.71.128:2379&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER&#x3D;&quot;node1&#x3D;http:&#x2F;&#x2F;192.168.71.128:2380,node2&#x3D;http:&#x2F;&#x2F;192.168.71.129:2380&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN&#x3D;&quot;etcd-cluster&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE&#x3D;&quot;new&quot;</span><br></pre></td></tr></table></figure>
<p>3.检查健康状态及leader</p>
<h1 id="etcdctl-member-list"><a href="#etcdctl-member-list" class="headerlink" title="etcdctl member list"></a>etcdctl member list</h1><h1 id="etcdctl-cluster-health"><a href="#etcdctl-cluster-health" class="headerlink" title="etcdctl cluster-health"></a>etcdctl cluster-health</h1><p>4.添加flannel网络信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># etcdctl mk &#x2F;atomic.io&#x2F;network&#x2F;config &#39;&#123;&quot;Network&quot;:&quot;10.10.0.0&#x2F;16&quot;,&quot;SubnetMin&quot;:&quot;10.10.10.0&quot;,&quot;SubnetMax&quot;:&quot;10.10.50.0&quot;,&quot;Backend&quot;:&#123;&quot;Type&quot;:&quot;vxlan&quot;&#125;&#125;&#39;</span><br><span class="line"># etcdctl get &#x2F;atomic.io&#x2F;network&#x2F;config</span><br><span class="line"># cat &#x2F;etc&#x2F;sysconfig&#x2F;flanneld</span><br><span class="line">FLANNEL_ETCD_ENDPOINTS&#x3D;&quot;http:&#x2F;&#x2F;192.168.71.128:2379&quot;</span><br><span class="line">FLANNEL_ETCD_PREFIX&#x3D;&quot;&#x2F;atomic.io&#x2F;network&quot;</span><br></pre></td></tr></table></figure>
<p>flannnel服务重启，会看到本机新添加的虚拟网卡</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">flannel.1: flags&#x3D;4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450</span><br><span class="line">        inet 10.10.19.0  netmask 255.255.255.255  broadcast 0.0.0.0</span><br><span class="line">        ether 6a:44:0e:24:86:eb  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 3  bytes 252 (252.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 3  bytes 252 (252.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure>

<p>5.将flannel的docker环境变量文件执行，可以生成docker的OPTS文件</p>
<h1 id="usr-libexec-flannel-mk-docker-opts-sh-c"><a href="#usr-libexec-flannel-mk-docker-opts-sh-c" class="headerlink" title="/usr/libexec/flannel/mk-docker-opts.sh -c"></a>/usr/libexec/flannel/mk-docker-opts.sh -c</h1><h1 id="cat-run-docker-opts-env"><a href="#cat-run-docker-opts-env" class="headerlink" title="cat /run/docker_opts.env"></a>cat /run/docker_opts.env</h1><p>DOCKER_OPTS=” –bip=10.10.19.1/24 –ip-masq=true –mtu=1450”<br>配置docker的service文件，将环境变量和启动选项添加上</p>
<h1 id="vim-lib-systemd-system-docker-service"><a href="#vim-lib-systemd-system-docker-service" class="headerlink" title="vim /lib/systemd/system/docker.service"></a>vim /lib/systemd/system/docker.service</h1><p>EnvironmentFile=/run/docker_opts.env #添加<br>$DOCKER_OPTS \  #启动参数添加</p>
<p>6.验证环境<br>docker服务重启,docker0的桥接网卡已经更新到flannel虚拟网卡的同一网段</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker0: flags&#x3D;4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450</span><br><span class="line">        inet 10.10.19.1  netmask 255.255.255.0  broadcast 0.0.0.0</span><br><span class="line">        ether 02:42:60:0f:91:9e  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 13  bytes 844 (844.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 5  bytes 378 (378.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure>
<p>两台主机上创建docker容器，并检查网卡信息,与docker0在同一网段，并且容器内部可以互相ping通。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">eth0      Link encap:Ethernet  HWaddr 02:42:0A:0A:13:02</span><br><span class="line">          inet addr:10.10.19.2  Bcast:0.0.0.0  Mask:255.255.255.0</span><br><span class="line">          inet6 addr: fe80::42:aff:fe0a:1302&#x2F;64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1</span><br><span class="line">          RX packets:5 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:13 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0</span><br><span class="line">          RX bytes:378 (378.0 B)  TX bytes:1026 (1.0 KiB)</span><br></pre></td></tr></table></figure>
<p>端口访问也都可以互通<br>7.原理深究<br>docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450<br>        inet 10.10.19.1  netmask 255.255.255.0  broadcast 0.0.0.0<br>        ether 02:42:60:0f:91:9e  txqueuelen 0  (Ethernet)<br>        RX packets 51  bytes 2654 (2.5 KiB)<br>        RX errors 0  dropped 0  overruns 0  frame 0<br>        TX packets 44  bytes 3514 (3.4 KiB)<br>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0<br>flannel.1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450<br>        inet 10.10.19.0  netmask 255.255.255.255  broadcast 0.0.0.0<br>        ether 6a:44:0e:24:86:eb  txqueuelen 0  (Ethernet)<br>        RX packets 31  bytes 1760 (1.7 KiB)<br>        RX errors 0  dropped 0  overruns 0  frame 0<br>        TX packets 27  bytes 1496 (1.4 KiB)<br>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0<br>[root@kube-master ~]# route -n<br>Kernel IP routing table<br>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface<br>0.0.0.0         192.168.71.2    0.0.0.0         UG    100    0        0 ens33<br>10.10.0.0       0.0.0.0         255.255.0.0     U     0      0        0 flannel.1<br>10.10.19.0      0.0.0.0         255.255.255.0   U     0      0        0 docker0<br>172.18.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker_gwbridge</p>
]]></content>
      <tags>
        <tag>docker</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>awk-special</title>
    <url>/2021/04/19/awk-special/</url>
    <content><![CDATA[<p>概论<br>awk的基本语法格式 awk -F ‘{patten +action}’ filename<br>支持自定义分隔符，正则表达式，自定义变量数组<br>支持内置变量 NF(列)，NR(行)<br>支持函数print，splite,substr,sub,gsub<br>支持流控制语句，类C语言，if,while,do/while,for,break,continue<br>1.获取一月份的薪资总额，并将级别文本显示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]# cat filetest</span><br><span class="line">Tom   0 2012-12-11 car 3000</span><br><span class="line">John  1 2013-01-13 bike 1000</span><br><span class="line">vivi  1 2013-01-18 car 2800</span><br><span class="line">Tom   0 2013-01-20 car 2500</span><br><span class="line">John  1 2013-01-28 bike 3500</span><br><span class="line">[root@centos-7 logs]# cat awkfile</span><br><span class="line">&#123;</span><br><span class="line">	splite($3,date,&quot;-&quot;);</span><br><span class="line">	if(date[2]&#x3D;&#x3D;&quot;01&quot;)&#123;</span><br><span class="line">		sal[$1]+&#x3D;$5</span><br><span class="line">	&#125;;</span><br><span class="line">	if($2&#x3D;&#x3D;&quot;0&quot;)&#123;</span><br><span class="line">		role[$1]&#x3D;&quot;manager&quot;</span><br><span class="line">	&#125;</span><br><span class="line">	else&#123;</span><br><span class="line">		role[$1]&#x3D;&quot;worker&quot;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">END&#123;</span><br><span class="line">   for(i in sal)&#123;</span><br><span class="line">          print i &quot;\t&quot; sal[i] &quot;\t&quot; role[i]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2.在abcd 的b后面插入3个字段efg<br>OFS重建$0,修改$3会根据OFS重建$0，OFS默认为’ ‘</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;a b c        d  &quot; | awk -F&quot; &quot; &#39;&#123;$3&#x3D;&quot;e f g &quot;$3;print $0&#125;&#39;</span><br></pre></td></tr></table></figure>
<p>3.格式化每行的前缀后缀空白，并将各部分左对齐</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]# cat testfile</span><br><span class="line">       aaa    bbb   ccc</span><br><span class="line">  ddd   ff        gg       hh        iiiii</span><br><span class="line">hhhhhh     jjj        kkk    h</span><br><span class="line">[root@centos-7 logs]# awk &#39;BEGIN&#123;OFS&#x3D;&quot;\t&quot;&#125;&#123;$2&#x3D;$2;print $0&#125;&#39; testfile</span><br><span class="line">[root@centos-7 logs]# awk &#39;&#123;$2&#x3D;$2;print $0&#125;&#39; testfile</span><br></pre></td></tr></table></figure>
<p>3.筛选ipv4地址，除了lo网卡之外的所有IPV4地址</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ifconfig | awk  &#39;&#x2F;inet&#x2F;&amp;&amp; !&#x2F;inet6&#x2F; &amp;&amp; $2!~&quot;^127&quot;&#123;print $2&#125;&#39;</span><br></pre></td></tr></table></figure>
<p>默认情况下awk按行读取，可以修改为安段落读取<br>RS=”” 按照段落读取<br>RS=”\0” 一次性读取所有数据，但有些特殊字符文件中包含了空字符\0<br>RS=”\n+” 按行读取，但忽略所有空行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]#  ifconfig | awk &#39;BEGIN&#123;RS&#x3D;&quot;&quot;&#125;!&#x2F;^lo:&#x2F;&#123;print $6&#125;&#39;</span><br><span class="line">[root@centos-7 logs]#  ifconfig | awk &#39;BEGIN&#123;RS&#x3D;&quot;&quot;&#125;!&#x2F;^lo:&#x2F;&#123;print $0&#125;&#39; | awk &#39;&#x2F;inet &#x2F;&#123;print $2&#125;&#39;</span><br></pre></td></tr></table></figure>
<p>4.处理ini配置文件<br>getline返回值</p>
<blockquote>
<p>0 表示已经读取到数据<br>=0 表示遇到结尾EOF,也就是表示没有读取到东西<br>&lt;0 表示读取报错</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]# awk &#39;index($0,&quot;[mysql]&quot;)&#123;print;while((getline var)&gt;0)&#123;if(var ~&#x2F;\[.*\]&#x2F;)&#123; exit &#125; print var&#125;&#125;&#39; mysql.ini</span><br><span class="line">[root@centos-7 logs]#awk &#39;BEGIN&#123;RS&#x3D;&quot;&quot;&#125;&#x2F;\[mysql\]&#x2F;&#39; mysql.ini</span><br><span class="line">[root@centos-7 logs]# cat mysql.ini</span><br><span class="line">[base]</span><br><span class="line">name&#x3D;os_repo</span><br><span class="line">enable&#x3D;1</span><br><span class="line">[mysql]</span><br><span class="line">name&#x3D;mysql_repo</span><br><span class="line">[epel]</span><br><span class="line">gpgcheck&#x3D;1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>5.根据字段去重</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]# awk -F &quot;?&quot; &#39;&#123;arr[$2]&#x3D;arr[$2]+1;if(arr[$2]&#x3D;&#x3D;1)&#123;print $2&#125;&#125;&#39; uniq</span><br><span class="line">uid&#x3D;123</span><br><span class="line">uid&#x3D;333</span><br><span class="line">uid&#x3D;9710</span><br><span class="line">[root@centos-7 logs]# cat uniq</span><br><span class="line">2019-01-13_index?uid&#x3D;123</span><br><span class="line">2019-01-13_index?uid&#x3D;123</span><br><span class="line">2019-01-13_index?uid&#x3D;333</span><br><span class="line">2019-01-13_index?uid&#x3D;9710</span><br><span class="line">2019-01-13_index?uid&#x3D;123</span><br><span class="line">2019-01-13_index?uid&#x3D;333</span><br><span class="line">2019-01-13_index?uid&#x3D;9710</span><br><span class="line">[root@centos-7 logs]# awk -F &quot;?&quot; &#39;!arr[$2]++&#39; uniq</span><br></pre></td></tr></table></figure>
<p>6.awk次数统计</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]# cat freq</span><br><span class="line">port</span><br><span class="line">port</span><br><span class="line">status</span><br><span class="line">status</span><br><span class="line">nfs</span><br><span class="line">status</span><br><span class="line">nfs</span><br><span class="line">status</span><br><span class="line">port</span><br><span class="line">[root@centos-7 logs]# awk &#39;&#123;arr[$1]&#x3D;arr[$1]+1&#125;END&#123;for(i in arr)&#123;print i &quot;\t&quot; arr[i]&#125;&#125;&#39; freq</span><br></pre></td></tr></table></figure>
<p>统计tcp连接状态的数量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]# netstat -tanp  | awk &#39;&#x2F;^tcp&#x2F;&#123;arr[$6]++&#125;END &#123;for(i in arr)&#123;print  arr[i], i&#125;&#125;&#39;</span><br></pre></td></tr></table></figure>
<p>awk中提供的排序函数,PROCINFO[“sorted_in”]=”@val_nnum_desc”<br>[root@centos-7 logs]# awk ‘{arr[$1]=arr[$1]+1}END{ PROCINFO[“sorted_in”]=”@val_num_desc”;for(i in arr){print arr[i] “\t” i}}’ freq<br>7.统计独立IP<br>统计每个url的独立访问IP有多少个(去重)，并且要为每个url保存一个对应的文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]# cat awk.sh</span><br><span class="line">BEGIN&#123;</span><br><span class="line">  FS&#x3D;&quot;|&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">if(!arr[$1,$2]++)&#123;</span><br><span class="line">     arr1[$1]++</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">END&#123;</span><br><span class="line">   for(i in arr1)&#123;</span><br><span class="line">      print i,arr1[i]&gt;(i&quot;.txt&quot;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[root@centos-7 logs]# cat access.log</span><br><span class="line">a.com.cn|202.19.43.22|2015-11-20 12:23:22|guest</span><br><span class="line">b.com.cn|202.19.43.22|2015-11-20 12:23:22|guest</span><br><span class="line">c.com.cn|202.19.43.24|2015-11-20 12:23:22|guest</span><br><span class="line">a.com.cn|202.19.43.22|2015-11-20 12:23:22|guest</span><br><span class="line">b.com.cn|202.19.43.33|2015-11-20 12:23:22|guest</span><br><span class="line">a.com.cn|202.19.43.22|2015-11-20 12:23:22|guest</span><br><span class="line">a.com.cn|202.19.43.22|2015-11-20 12:23:22|guest</span><br><span class="line">c.com.cn|202.19.43.24|2015-11-20 12:23:22|guest</span><br><span class="line">c.com.cn|202.19.43.25|2015-11-20 12:23:22|guest</span><br><span class="line">b.com.cn|202.19.43.22|2015-11-20 12:23:22|guest</span><br></pre></td></tr></table></figure>
<p>8.处理字段缺失</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]# cat loss</span><br><span class="line">ID name  gender age email</span><br><span class="line">1  Bob   male   28  qq.com</span><br><span class="line">2  Alice female     123.com</span><br><span class="line">3  Tony  male   35  163.com</span><br><span class="line">4        male   22  edu.com</span><br><span class="line">5  Jerry male   21</span><br><span class="line">[root@centos-7 logs]# cat lossawk</span><br><span class="line">BEGIN&#123;</span><br><span class="line">  FIELDWIDTHS&#x3D;&quot;2 6 7 4 8&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">print $2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>若字段中包含分隔符，数据的处理，FPAT可以收集正则匹配的结果，并将它们保存在各个字段中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]# cat inlude</span><br><span class="line">Robin,Arnold,&quot;1234 A Pretty Street,NE&quot;,MyTown,MyState,12345-6789,USA</span><br><span class="line">Roban,Arlnold,&quot;5678 A Pretty Street,NE&quot;,MyTown,MyState,12345-6789,USA</span><br><span class="line">[root@centos-7 logs]# cat awkinclude</span><br><span class="line">BEGIN&#123;</span><br><span class="line">   FPAT&#x3D;&quot;[^,]+|\&quot;.*\&quot;&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">print $1,$3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>匹配不包含逗号结束的，或者包含双引号的，以此来分隔文本<br>9.取字段中的指定字符数量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos-7 logs]# awk &#39;&#123;print $1,substr($2,0,3)&#125;&#39; given</span><br><span class="line">[root@centos-7 logs]# cat given</span><br><span class="line">14 0013adsdwescs</span><br><span class="line">23 dfsf3425wrdsd</span><br><span class="line">54 wrewrcerwrwss</span><br><span class="line">[root@centos-7 logs]# awk &#39;BEGIN&#123;FIELDWIDTHS&#x3D;&quot;2 4&quot;&#125;&#123;print $1,$2&#125;&#39; given</span><br><span class="line">14  001</span><br><span class="line">23  dfs</span><br><span class="line">54  wre</span><br></pre></td></tr></table></figure>
<p>10.行列转换</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>11.筛选给定时间范围内的日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bash-4.2# awk &#39;BEGIN&#123;print mktime(&quot;2019 11 10 8 23 29&quot;)&#125;&#39;</span><br><span class="line">1573345409</span><br><span class="line">bash-4.2# date --d &#39;@1573345409&#39;</span><br><span class="line">Sun Nov 10 08:23:29 CST 2019</span><br><span class="line">bash-4.2# cat timeawk</span><br><span class="line">BEGIN&#123;</span><br><span class="line">  str&#x3D;&quot;2019-11-10T20:25:39+08:00&quot;</span><br><span class="line">  print strptime(str)</span><br><span class="line">&#125;</span><br><span class="line">function strptime(str,arr,Y,M,D,H,m,S)&#123;</span><br><span class="line">  patsplit(str,arr,&quot;[0-9]&#123;1,4&#125;&quot;)</span><br><span class="line">  Y&#x3D;arr[1]</span><br><span class="line">  M&#x3D;arr[2]</span><br><span class="line">  D&#x3D;arr[3]</span><br><span class="line">  H&#x3D;arr[4]</span><br><span class="line">  m&#x3D;arr[5]</span><br><span class="line">  S&#x3D;arr[6]</span><br><span class="line">  return  mktime(sprintf(&quot;%s %s %s %s %s %s&quot;,Y,M,D,H,m,S))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>匹配大于某一时间之后的日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bash-4.2# cat timeawk</span><br><span class="line">BEGIN&#123;</span><br><span class="line">   timepoint&#x3D;&quot;07&#x2F;12&#x2F;2018:01:27:39&quot;</span><br><span class="line">   point&#x3D;strptime(timepoint)</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line"> str&#x3D;$4;</span><br><span class="line"> split(str,date,&quot;[&quot;);</span><br><span class="line"> if(strptime(date[2])&gt;point)&#123;</span><br><span class="line">        print $0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">function strptime(str,arr,Y,M,D,H,m,S)&#123;</span><br><span class="line">  patsplit(str,arr,&quot;[0-9]&#123;1,4&#125;&quot;)</span><br><span class="line">  D&#x3D;arr[1]</span><br><span class="line">  M&#x3D;arr[2]</span><br><span class="line">  Y&#x3D;arr[3]</span><br><span class="line">  H&#x3D;arr[4]</span><br><span class="line">  m&#x3D;arr[5]</span><br><span class="line">  S&#x3D;arr[6]</span><br><span class="line">  return  mktime(sprintf(&quot;%s %s %s %s %s %s&quot;,Y,M,D,H,m,S))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另外如果匹配的是月份，可以再定义一个map函数，将月份字符串映射为十进制字符串。<br>gensub(a,b,c[,d])全局替换，匹配正则a， 用b替换，c为指定替换目标是第几次匹配，d为指定替换目标是哪个域如$1,$2，若无d指$0，返回值为target替换后内容(未替换还是返回 target原内容)，与sub、gsub不同的是，target内容替换后不改变。<br>gensub(/123/,”x”,1,$1)替换$1中 第一次匹配到的123为字符x，返回值为$1替换后的内容，且$1的内容并没有改变<br>gensub(/a(.<em>)b/,”\1”,1) 返回值为匹配正则第1对()内的内容<br>gensub(/a(.</em>)b(.*)c/,”\2”,1) 返回值为匹配正则第2对()内的内容<br>12.去掉段落注释</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bash-4.2# cat code</span><br><span class="line">&#x2F;* this is a anotate *&#x2F;</span><br><span class="line">if a&gt; 0 &#x2F;* case one</span><br><span class="line">the number a is positive *&#x2F; then</span><br><span class="line">cout&lt;&lt;&quot;a&gt;0&quot;</span><br><span class="line">else &#x2F;* case two a is neggative *&#x2F;</span><br><span class="line">cout&lt;&lt;&quot;a&lt;0&quot;</span><br><span class="line">fi</span><br><span class="line">&#x2F;* the end *&#x2F;</span><br><span class="line">bash-4.2# cat codeawk</span><br></pre></td></tr></table></figure>

<h4 id=""><a href="#" class="headerlink" title=""></a></h4><p>sed的使用专题<br>1.多个匹配的的处理<br>使用分号分隔指令，在每个指令前放置-e,使用 单引号后换行多行输入<br>2.阻止输入行的自动显示<br>-n<br>3.扩展正则表达式<br>+?|(){}<br>4.细节<br>^和$只在匹配行首和行尾是有特殊意义，如果在中间，将是本意，，ab^c,是^原本的含义字符a<br>5.分组命令<br>sed /d/,/ds/{/ouba/d} list<br>6.</p>
]]></content>
      <tags>
        <tag>awk</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>go-language</title>
    <url>/2021/05/07/go-language-0/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>k8s-code</title>
    <url>/2021/05/07/k8s-code/</url>
    <content><![CDATA[<p>1.apiserver<br>API 的URL大致以 /apis/group/version/namespaces/my-ns/myresource 组成</p>
]]></content>
      <tags>
        <tag>k8s</tag>
        <tag>code</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix</title>
    <url>/2021/05/06/zabbix/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>asyncio</title>
    <url>/2021/05/26/asyncio/</url>
    <content><![CDATA[<p>1.协程<br>协程不是计算机提供的，程序员认为创造<br>协程也可以称为微线程，是一种用户态的上下文切换技术，简言之，就是通过一个线程实现代码块相互却换执行<br>实现协程的方法：</p>
<ul>
<li>greenlet</li>
<li>yield关键字</li>
<li>asyncio装饰器(python3.4)</li>
<li>async，await关键字[python3.5 推荐]</li>
</ul>
<p>1.1greenlet实现协程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from greenlet import  greenlet</span><br><span class="line">def func1():</span><br><span class="line">    print(1)</span><br><span class="line">    gr2.switch()</span><br><span class="line">    print(2)</span><br><span class="line">    gr2.switch()</span><br><span class="line"></span><br><span class="line">def func2():</span><br><span class="line">    print(3)</span><br><span class="line">    gr1.switch()</span><br><span class="line">    print(4)</span><br><span class="line"></span><br><span class="line">gr1&#x3D;greenlet(func1)</span><br><span class="line">gr2&#x3D;greenlet(func2)</span><br><span class="line">gr1.switch()</span><br></pre></td></tr></table></figure>
<p>特点：会从上次swich的地方往后执行，不会产生死锁<br>1.2yeild关键字</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def func1():</span><br><span class="line">    yield 1</span><br><span class="line">    yield from func2()</span><br><span class="line">    yield 2</span><br><span class="line"></span><br><span class="line">def func2():</span><br><span class="line">    yield 3</span><br><span class="line">    yield 4</span><br><span class="line"></span><br><span class="line">f1&#x3D;func1()</span><br><span class="line">for item in f1:</span><br><span class="line">    print(item)</span><br></pre></td></tr></table></figure>
<p>缺点：比较牵强，每次从函数起始处开始执行，可能会产生死锁<br>1.3asyncio</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">@asyncio.coroutine</span><br><span class="line">def func1():</span><br><span class="line">    print(1)</span><br><span class="line">    #如果网络请求，下载一张图片</span><br><span class="line">    yield from asyncio.sleep(2) #遇到IO耗时操作，自动化切换到tasks中其他任务</span><br><span class="line">    print(2)</span><br><span class="line">@asyncio.coroutine</span><br><span class="line">def func2():</span><br><span class="line">    print(3)</span><br><span class="line">    yield from asyncio.sleep(2) # 遇到IO耗时操作，自动化切换到tasks中其他任务</span><br><span class="line">    print(4)</span><br><span class="line"></span><br><span class="line">tasks&#x3D;[</span><br><span class="line">    asyncio.ensure_future(func1()),</span><br><span class="line">    asyncio.ensure_future(func2())</span><br><span class="line">]</span><br><span class="line">loop&#x3D;asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br></pre></td></tr></table></figure>
<p>1.4asunc&amp;&amp;await关键字<br>import asyncio<br>async def func1():<br>    print(1)<br>    #如果网络请求，下载一张图片<br>    await asyncio.sleep(2) #遇到IO耗时操作，自动化切换到tasks中其他任务<br>    print(2)</p>
<p>async def func2():<br>    print(3)<br>    await asyncio.sleep(2) # 遇到IO耗时操作，自动化切换到tasks中其他任务<br>    print(4)</p>
<p>tasks=[<br>    asyncio.ensure_future(func1()),<br>    asyncio.ensure_future(func2())<br>]<br>loop=asyncio.get_event_loop()<br>loop.run_until_complete(asyncio.wait(tasks))</p>
<p>2.协程的意义<br>在一个线程中，如果遇到IO等待的时间，线程不会傻等利用空闲的时候再去干点其他事情<br>案例：下载三张图(有网络IO)。</p>
<ul>
<li>普通方式</li>
<li>协程的异步方式<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import aiohttp</span><br><span class="line">import asyncio</span><br><span class="line">async def fetch(session,url):</span><br><span class="line">    print(&quot;发送请求:&quot;,url)</span><br><span class="line">    async with session.get(url,verify_ssl&#x3D;False) as response:</span><br><span class="line">        content&#x3D;await response.content.read()</span><br><span class="line">        file_name&#x3D;url.rsplit(&#39;_&#39;)[-1]</span><br><span class="line">        with open(file_name, mode&#x3D;&#39;wb&#39;) as file_object:</span><br><span class="line">             file_object.write(content)</span><br><span class="line">async def main():</span><br><span class="line">    async with aiohttp.ClientSession() as session:</span><br><span class="line">        url_list&#x3D;[</span><br><span class="line">        &#39;https:&#x2F;&#x2F;hellorfss.zcool.cn&#x2F;image-stock&#x2F;shutterstock&#x2F;photos&#x2F;1776021896&#x2F;display_1500&#x2F;stock-photo-1776021896.jpg?auth_key&#x3D;1622016134-0-0-58aecf24d6d9e5fbeb036e02e692d626&#39;,</span><br><span class="line">        &#39;https:&#x2F;&#x2F;hellorfss.zcool.cn&#x2F;image-stock&#x2F;shutterstock&#x2F;photos&#x2F;1776021896&#x2F;display_1500&#x2F;stock-photo-1776021896.jpg?auth_key&#x3D;1622016134-0-0-58aecf24d6d9e5fbeb036e02e692d626&#39;,</span><br><span class="line">        &#39;https:&#x2F;&#x2F;hellorfss.zcool.cn&#x2F;image-stock&#x2F;shutterstock&#x2F;photos&#x2F;1776021896&#x2F;display_1500&#x2F;stock-photo-1776021896.jpg?auth_key&#x3D;1622016134-0-0-58aecf24d6d9e5fbeb036e02e692d626&#39;</span><br><span class="line">        ]</span><br><span class="line">        tasks&#x3D;[asyncio.create_task(fetch(session,url)) for url in url_list]</span><br><span class="line">        await asyncio.wait(tasks)</span><br><span class="line"></span><br><span class="line">if __name__&#x3D;&#x3D;&#39;__main__&#39;:</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure></li>
</ul>
<p>3.异步编程<br>3.1事件循环<br>理解成为一个死循环，去检测并执行代码<br>3.2快速上手<br>async def<br>协程对象，执行协程函数(),得到协程对象<br>async def func()<br>    pass<br>result=func()<br>协程函数创建协程对象，函数内部代码不会执行</p>
<p>async def func()<br>    pass<br>result=func()<br>loop=async.get_event_loop()<br>loop.run_util_complete(result)<br>//或者简洁的写法 async.run(result) //python3.7</p>
<p>3.3await<br>await+可等待的对象(协程对象，Future,Task对象-&gt;io等待)<br>import asyncio<br>async def func():<br>    print(“lalal”)<br>    response=await asyncio.sleep(2)<br>    print(“end”,response)<br>asyncio.run(func())<br>两个函数之间切换</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def others():</span><br><span class="line">    print(&quot;start&quot;)</span><br><span class="line">    await asyncio.sleep(2)</span><br><span class="line">    print(&#39;end&#39;)</span><br><span class="line">    return &#39;return&#39;</span><br><span class="line">async def func():</span><br><span class="line">    print(&quot;lalal&quot;)</span><br><span class="line">    response&#x3D;await others()</span><br><span class="line">    print(&quot;end&quot;,response)</span><br><span class="line"></span><br><span class="line">asyncio.run(func())</span><br></pre></td></tr></table></figure>
<p>await就是等待对象的值得到结果之后再继续往下走<br>3.4 Task对象<br>事件循环中添加多个任务的。<br>Tasks用于并发调度协程，通过asyncio.create_tasks(协程对象)的方式创建Task对象，这样可以让协程加入事件的循环中等待被调度执行。<br>除了使用async.create_task()函数以外，还可以用低层级的loop.create_task()或ensure_future()函数，不建议手动实例化Task对象<br>注意：async.create_tasks()函数在python3.7中被加入，在python3.7以前，可以改用低层级的async.ensure_future()函数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def func():</span><br><span class="line">    print(1)</span><br><span class="line">    await asyncio.sleep(2)</span><br><span class="line">    print(2)</span><br><span class="line">    return &quot;返回値&quot;</span><br><span class="line">async def main():</span><br><span class="line">    print(&quot;main开始&quot;)</span><br><span class="line">    #創建Task対象，將当前抗行func函数任努添加到事件循坏。</span><br><span class="line">    task1 &#x3D; asyncio.create_task(func())</span><br><span class="line">    task2 &#x3D; asyncio.create_task(func())</span><br><span class="line">    print(&quot;main結束&quot;)</span><br><span class="line">    #当抗行某め程遇到IO操作肘，会自劫化切換抗行其他任努。</span><br><span class="line">    #此赴的awai t是等待相対座的か程全都抗行完罕并荻取結果</span><br><span class="line">    ret1 &#x3D; await task1</span><br><span class="line">    ret2 &#x3D; await task2</span><br><span class="line">    print(ret1, ret2)</span><br><span class="line">asyncio. run( main())</span><br></pre></td></tr></table></figure>
<p>事件循环</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def func():</span><br><span class="line">    print(1)</span><br><span class="line">    await asyncio.sleep(2)</span><br><span class="line">    print(2)</span><br><span class="line">    return &quot;返回値&quot;</span><br><span class="line">async def main():</span><br><span class="line">    print(&quot;main开始&quot;)</span><br><span class="line">    #創建Task対象，將当前抗行func函数任努添加到事件循坏。</span><br><span class="line">    task_lisk&#x3D;[</span><br><span class="line">     asyncio.create_task(func(),name&#x3D;&#39;n1&#39;), &#x2F;&#x2F;会加入到事件队列</span><br><span class="line">     asyncio.create_task(func(),name&#x3D;&#39;n2&#39;)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    print(&quot;main結束&quot;)</span><br><span class="line">    #当抗行某め程遇到IO操作肘，会自劫化切換抗行其他任努。</span><br><span class="line">    #此赴的awai t是等待相対座的か程全都抗行完罕并荻取結果</span><br><span class="line">    done,pending&#x3D; await asyncio.wait(task_lisk,timeout&#x3D;None)</span><br><span class="line">    print(done)</span><br><span class="line">asyncio.run( main()) &#x2F;&#x2F;会创建事件队列</span><br></pre></td></tr></table></figure>
<p>注意，是先创建事件队列，再将任务加入事件队列<br>如果去掉main函数，会有问题，报错：RuntimeError: no running event loop</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def func():</span><br><span class="line">    print(1)</span><br><span class="line">    await asyncio.sleep(2)</span><br><span class="line">    print(2)</span><br><span class="line">    return &quot;返回値&quot;</span><br><span class="line">task_lisk&#x3D;[</span><br><span class="line">     asyncio.create_task(func()), &#x2F;&#x2F;会将任务加入到事件队列，但是事件队列还没有被创建</span><br><span class="line">     asyncio.create_task(func())</span><br><span class="line">    ]</span><br><span class="line">done,pending&#x3D;asyncio. run(asyncio.wait(task_lisk))</span><br><span class="line">print(done)</span><br></pre></td></tr></table></figure>
<p>继续调整，task列表中放协程对象，先不创建task对象</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def func():</span><br><span class="line">    print(1)</span><br><span class="line">    await asyncio.sleep(2)</span><br><span class="line">    print(2)</span><br><span class="line">    return &quot;返回値&quot;</span><br><span class="line">task_lisk&#x3D;[</span><br><span class="line">     func(),</span><br><span class="line">     func()</span><br><span class="line">    ]</span><br><span class="line">done,pending&#x3D;asyncio.run(asyncio.wait(task_lisk))</span><br><span class="line">print(done)</span><br></pre></td></tr></table></figure>
<p>task对象是立即将事件放入事件队列中<br>3.5 asyncio的Future对象<br>更偏向于底层，是task类的基类，_state维护状态如果是finished,会从队列中删除<br>示例1:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def main():</span><br><span class="line">    #获取当前时间循环</span><br><span class="line">    loop&#x3D;asyncio.get_running_loop()</span><br><span class="line">    #创建一个任务Future对象，这个任务什么都不干</span><br><span class="line">    fut&#x3D;loop.create_future()</span><br><span class="line">    #等待任务的最终结果哟Future对象，没有结果会一直等下去</span><br><span class="line">    await fut</span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>
<p>示例2:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">async def set_after(fut):</span><br><span class="line">    await asyncio.sleep(2)</span><br><span class="line">    fut.set_result(&quot;666&quot;)</span><br><span class="line">async def main():</span><br><span class="line">    #获取当前时间循环</span><br><span class="line">    loop&#x3D;asyncio.get_running_loop()</span><br><span class="line">    #创建一个任务Future对象，这个任务什么都不干</span><br><span class="line">    fut&#x3D;loop.create_future()</span><br><span class="line">    #等待任务的最终结果哟Future对象，没有结果会一直等下去</span><br><span class="line">    await loop.create_task(set_after(fut))</span><br><span class="line">    data&#x3D;await fut</span><br><span class="line">    print(data)</span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>
<p>3.5 cocurrent futures.Future对象<br>使用线程池，进程池实现异步操作时用到的对象</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line">from concurrent.futures import Future</span><br><span class="line">from concurrent.futures.thread import ThreadPoolExecutor</span><br><span class="line">from concurrent.futures.process import ProcessPoolExecutor</span><br><span class="line">def func(value):</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print(value)</span><br><span class="line">#创建线程池</span><br><span class="line">pool&#x3D;ThreadPoolExecutor(max_workers&#x3D;5)</span><br><span class="line">#创建进程池</span><br><span class="line">#pool&#x3D;ProcessPoolExecutor(max_workers&#x3D;5)</span><br><span class="line">for i in range(10):</span><br><span class="line">    fut&#x3D;pool.submit(func,i)</span><br><span class="line">    print(fut)</span><br></pre></td></tr></table></figure>
<p>以后写代码可能会存在交叉时间，例如：CRM项目80%基于协程异步编程[线程，进程做异步编程]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import requests</span><br><span class="line">import asyncio</span><br><span class="line"></span><br><span class="line">async def download_image(url):</span><br><span class="line">    print(&quot;开始下载:&quot;+url)</span><br><span class="line">    loop&#x3D;asyncio.get_event_loop()</span><br><span class="line">    future&#x3D;loop.run_in_executor(None,requests.get,url)</span><br><span class="line"></span><br><span class="line">    response&#x3D;await future</span><br><span class="line">    print(&quot;下载完成&quot;)</span><br><span class="line">    file_name&#x3D;url.rsplit(&#39;-&#39;)[-1]</span><br><span class="line">    with open(file_name,mode&#x3D;&#39;wb&#39;) as file_object:</span><br><span class="line">        file_object.write(response.content)</span><br><span class="line">if __name__&#x3D;&#x3D;&#39;__main__&#39;:</span><br><span class="line">    url_list&#x3D;[</span><br><span class="line">        &#39;https:&#x2F;&#x2F;hellorfss.zcool.cn&#x2F;image-stock&#x2F;shutterstock&#x2F;photos&#x2F;1776021896&#x2F;display_1500&#x2F;stock-photo-1776021896.jpg?auth_key&#x3D;1622016134-0-0-58aecf24d6d9e5fbeb036e02e692d626&#39;,</span><br><span class="line">        &#39;https:&#x2F;&#x2F;hellorfss.zcool.cn&#x2F;image-stock&#x2F;shutterstock&#x2F;photos&#x2F;1776021896&#x2F;display_1500&#x2F;stock-photo-1776021896.jpg?auth_key&#x3D;1622016134-0-0-58aecf24d6d9e5fbeb036e02e692d626&#39;,</span><br><span class="line">        &#39;https:&#x2F;&#x2F;hellorfss.zcool.cn&#x2F;image-stock&#x2F;shutterstock&#x2F;photos&#x2F;1776021896&#x2F;display_1500&#x2F;stock-photo-1776021896.jpg?auth_key&#x3D;1622016134-0-0-58aecf24d6d9e5fbeb036e02e692d626&#39;</span><br><span class="line">    ]</span><br><span class="line">    tasks&#x3D;[download_image(url) for url in url_list]</span><br><span class="line">    loop&#x3D;asyncio.get_event_loop()</span><br><span class="line">    loop.run_until_complete(asyncio.wait(tasks))</span><br></pre></td></tr></table></figure>
<p>3.6异步迭代器<br>什么是异步迭代器，实现了aiter和anext的方法对象<br>什么是异步可迭代对象，可在async for语句中被使用的对象，必须通过它的aiter方法返回一个asynchronous.iterator</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">class Reader(object):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.count&#x3D;0</span><br><span class="line">    async def readline(self):</span><br><span class="line">        #await async.sleep(1)</span><br><span class="line">        self.count+&#x3D;1</span><br><span class="line">        if self.count&#x3D;&#x3D;100:</span><br><span class="line">            return None</span><br><span class="line">        return self.count</span><br><span class="line"></span><br><span class="line">    def __aiter__(self):</span><br><span class="line">        return self</span><br><span class="line">    async def __anext__(self):</span><br><span class="line">        val&#x3D;await self.readline()</span><br><span class="line">        if val&#x3D;&#x3D;None:</span><br><span class="line">            raise StopAsyncIteration</span><br><span class="line">        return val</span><br><span class="line">async def main():</span><br><span class="line">    obj&#x3D;Reader()</span><br><span class="line">    async for item in obj:</span><br><span class="line">        print(item)</span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>
<p>3.7异步上下文管理器<br>此种对象通过定义__aenter()和阿 exit()方法来对async with语句中的环境进行控制</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">class AsyncContestManager:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.conn&#x3D;&quot;&quot;</span><br><span class="line">    async def do_something(self):</span><br><span class="line">        return 666</span><br><span class="line">    async def __aenter__(self):</span><br><span class="line">        #异步连接数据库</span><br><span class="line">        #self.conn&#x3D;await asyncio.sleep(1)</span><br><span class="line">        return self</span><br><span class="line">    async def __aexit__(self,exe_type,exc,tb):</span><br><span class="line">        #异步关闭数据库</span><br><span class="line">        await asyncio.sleep(1)</span><br><span class="line">async def fun():</span><br><span class="line">    async with AsyncContestManager() as f:</span><br><span class="line">        result&#x3D;await f.do_something()</span><br><span class="line">        print(result)</span><br><span class="line">asyncio.run(fun())</span><br></pre></td></tr></table></figure>
<p>4.uvloop<br>是async的事件循环的替代方案</p>
]]></content>
      <tags>
        <tag>协程</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title>awr-analyse</title>
    <url>/2021/05/20/awr-analyse/</url>
    <content><![CDATA[<p>1.AWR简介<br>基础指标统计<br>SQL和优化器指标<br>os指标<br>等待事件类型<br>时间指标<br>度量<br>ASH Active session History<br>建议器advisor<br>快照指标<br>数据库特性使用情况<br>问题：session hung怎么处理?<br>数据库中MMON(Manageability Monitor Process)和它的小工进程m00x来维护awr,mmon进程hang意味着AWR不可用<br>诸行无常，盛者必衰<br>Sockets：CPU插槽（CPU插槽主要分为Socket、Slot这两种。就是用于安装CPU的插座。）<br>2.重要参数解析<br>Elapse: 拉取报告的时间<br>DB time: 所有前台session花费在database调用上的总和时间<br>   是foregroud sessions<br>   包括CPU时间，IO time和其他一系列非空闲等待时间<br>DB time描绘了数据库的总体负载，但要和elapsed time逝去时间结合<br>AAS:average active session,ash报告开篇即为AAS<br>AAS=DB time/Elapse time &lt;=1 负载轻<br>AAS=DB time/Elapse time &gt; 100 数据库hang<br>DB time + Non-idle wait + wait on cpu queue<br>如果仅有两个逻辑CPU,而2个session在60分钟都没有等待事件，一直跑在CPU上，那么：<br>DB CPU=2<em>60min DB time=2</em>60+0+0=120<br>AAS=120/60=2 正好等于OS load 2<br>如果有3个session都100%消耗CPU,那么总有一个要wait on queue<br>DB CPU=2*60min,wait on CPU queue=60mins<br>AAS=(120+60)/60=3-&gt;主机load也为3，此时vmstat看waiting for run time<br>真实世界中，DB CPU=xx mins Non-idle wait=enq:TX+coursor pin S on X+ latch:xxx + db file sequential read + …<br>有时间vmstat,top,iowait的使用要去找资料详细分析及故障定位<br>有脚本工具拉取7天的DB time，画db time的折线图</p>
<p>redo size单位bytes,redo size可以用来估量update/insert/delete的频率，大的redo size往往对lgwr写日志，和arch归档造成I/O压力，<br>per transaction可以用来分辨是大量小事物还是少量大事务。<br>Redo size (bytes):    56,318.1    8,353.5      属于不大不小的事物<br>                    1.5MB        6k ,则符合OLTP特征，大量的小事物<br>Logical read单位，次数<em>块数，逻辑读消耗CPU,主频和CPU核数都很重要，逻辑读则DB CPU往往高，也往往看到latch,cache,buffer chain等待<br>Block changes 单位次数</em>块数，描绘数据变化频率<br>Physical Read 单位次数块数，物理读消耗IO,体现在IOPS和吞吐量等不同的纬度上，但减少物理读可能意味着消耗更多的CPU<br>Physical writes单位次数*块数，主要是DBWR写datafile,也有direct path write。dbwr长期写出慢会导致定期的log file switch(check point not complete)检查点无法完成前台等待<br>Parse 解析次数，包括软解析+硬解析，软解析优化得不好，则夸张地说几乎等于每秒SQL执行次数，希望看到的是，解析一次到处运行<br>Hard Parse: 万恶之源，cursor pin s on X,library cache: mutex X,latch:row cache objects/share poll …硬解析最好少于每秒20次<br>时间模型 Time Model Statistics<br>parse time elapsed    474.58    3.59<br>hard parse elapsed time    450.84    3.41     硬解析敏感的<br>Latch Hit%：willing-to wait latch 闩申请不要等待的比例<br>Parse CPU To Parse Elapse:快照内解析CPU的时间和总的时间的比值（parse cpu time/parse elapse time)，若该指标水平很低，那么说明在整个解析过程中，整个在CPU上运算的时间是很短的<br>而主要的解析时间都耗费在各种其他非空闲的等待事件上了<br>%Non-parse CPU非解析CPU比例，公式为DB CPU-parse CPU)/DB CPU，若大多数的CPU都用在解析上了，则可能好钢没用在刀刃上<br>% SQL with executions&gt;1: 提供大致的SQL重用次数，若该数据的比例小于90%，可以使用相关SQL去抓硬编码的非绑定变量的SQL语句<br>db file sequential read 单块读等待，是一种最为常见的物理IO等待事件，这里的sequential指的是将数据块<br>读入到相连续的内存空间中(contiguous memory space)而不是指所读取的数据块是连续的，该等待事件可能在多种场景中发生<br>等待事件有蝴蝶效应</p>
<p>3.性能优化的多维度理论<br>增加了CPU-&gt;更大的并发量，更多的并发争用<br>调整了IO存储-&gt;更少的IO,更多的CPU计算，更高的CPU使用率<br>Redo写得慢-&gt;影响commit-&gt;造成enq:tx和gc buffer busy等待<br>datafile写得慢-&gt;检查点完不成，日志无法切换，前台DML hang<br>Sequence nocache-&gt;Insert index很容易造成enq:index contention,和row cache lock和enq:SQ<br>5.基础数据的理解<br>Thread(s) per core:    1 //每核可以同时运行的线程，大于1说明使用的超线程<br>Core(s) per socket:    2 // 每个CPU多少核<br>Socket(s):             1 // 1个物理CPU插槽<br>当硬件线程技术打开时，一个CPU core可以作为多个逻辑CPU<br>%Total CPU，该实例所使用的CPU占总CPU的比例-&gt; %of total CPU for instance<br>%Busy CPU，该实例所使用的CPU占总的CPU的比例-&gt;%of busy CPU for instance<br>例如共4个逻辑CPU，其中3个被完全使用，3个钟的1个完全被该实例使用，则%Total CPU=1/4=25%，而%Busy CPU=1/3=33%<br>当CPU高时一般看%Busy CPU可以确定CPU到底是否时本实例消耗的，还是主机上其他称他程序<br>%busy CPU for instance =(DB CPU+backgroud cpu time) /(busy_time/100)<br>% of total CPU for instance = DB CPU+background cpu time)/(BYSY TIE + IDLE_TIME)<br>%DB time waiting for CPU (Resource Manager) =(RSRC_MGR_CPU_WAIT_TIME/100)/DB TIME<br>反映由于resource manager quantum等待的时间,resmgr:cpu quantum等待事件是当resource manager控制CPU调度时，需要控制对应的进程暂时不使用CPU<br>而进程到内部运行队列中，以保证该进程对应 的consumer group(消费组)没有消耗比指定resource manager指令更多的CPU<br>游标绑定变量，游标共享，问题要再仔细看看查<br>connection management call elapsed time     连接耗费的时间<br>failed parse elapse time解析失败，例如由于ORA-04031</p>
<p>load Profile中的数据：<br>Physical writes单位 次数*块数，主要是DBWR写datafile，也有direct path write, dbwr长期写出慢会导致定期的log file switch(checkpoint no complete)检查点无法完成的前台等待。<br>‘Cursor: pin S on X’ 最常见的等待事件，进程为了共享操作例如执行pin游标而以SHRD S mode申请mutex，但是未立即获得。原因是该游标被其他进程以EXCL X mode 持有了</p>
]]></content>
      <tags>
        <tag>oracle</tag>
        <tag>awr</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx</title>
    <url>/2021/05/09/nginx/</url>
    <content><![CDATA[<p>1.概述<br>nginx使用基于事件驱动的架构能够并发处理百万级别的TCP链接，支持epoll，Nginx支持其独有的sendfile系统调用，这个系统调用可以高效地把硬<br>盘中的数据发送到网络上(不需要先把硬盘数据复制到用户态内存上再发送)，这极大地减少了内核态与用户态数据间的复制动作。一.般情况下，10000个非活跃的HTTP Keep-Alive连接在Nginx中仅消耗2.5MB的内存，这<br>是Nginx支持高并发连接的基础。</p>
]]></content>
      <tags>
        <tag>nginx</tag>
        <tag>develop</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle-rac</title>
    <url>/2021/05/15/oracle-rac/</url>
    <content><![CDATA[<p>1.oracle是比较大型的数据库，它怎样实现可扩展性？<br>   纵向扩容和横向扩容，RAC的缓存融合技术管理所有节点的数据缓存并保持一致，私有互联网络将各个RAC节点连接起来，传输集群心跳信息及节点间的共享数据<br> rac数据库，ASM实例，数据库服务，监听，VIP地址，ASM磁盘组和应用，它们都作为集群服务就绪服务(CRS)的资源存在于集群中，集群件将这些CRS资源状态存储在共享存储OCR上。<br> 全局资源目录GRD:数据块ID,哪个RAC实例保存了该数据块的最新版本，该数据块在每个数据库实例中被持有的锁模式<br> GCS：全局缓存服务，负责rac实例之间的数据块传输<br> GES: 全局队列服务，管理队列资源包括，库缓存锁，字典缓存锁，事物锁及表锁<br> 数据库实例失败的时候，实例上的会话正在进行DML操作，如插入，更新或者删除时，DML事物会被回滚，会话也将被重新连接到幸存的节点，此次事物的DML<br> 语句需要重新开始。<br> 修改客户端的TAF配置，故障切换模式由type参数指定，故障切换方法由method指定<br> 2.rac有哪些集群概念，启动顺序是怎样的？数据库挂起的分析是怎样的？<br> 集群注册表OCR和表决磁盘放在共享存储中，Oracle集群件的两个文件: OLR 和GPnP配置文件。都存储在本地文件系统中，放在每个RAC节点的网格主目录中。OLR是OCR的本地版本，它存储了本地节点元数据，由Oracle高可用性服务守护进程(OHASD)来管理。OLR存储的信息比OCR少，但OLR可以从本地存储中直接提供元数据，而不需要访问存储在ASM磁盘组中的OCR。每个节点都有自己的OLR配置文件，它的默认路径为$GIHOME/cdata/<hostname>.olr，这个路径记录在/etc/oracle/olr.loc文件中。<br> 第0级:通过操作系统的init进程，集群件自动启动。init进程仅派生init.ohasd进程，<br>init.ohasd再启动OHASD进程。这个派生的配置写在/etc/inittab文件里:<br>$cat /etc/inittablgrep init.d 1 grep -v grep<br>EBF Oracle Linux 6.x Fl Red Hat Linux 6.x F-HI J inittab X4, FTELF Жc.T. FIJRitj<br>init.ohasd j# FÉKJ X 14 /etc/init/oracle-ohasd.conf:<br>$ cat /etc/ init/oracle-ohasd. conf<br>start on runlevel[ 35]<br>stop on runlevel [ !35]<br>respawn<br>文件中的init.ohasd run部分启动了ohasd.bin后台进程:<br>$ ps -ef l grep ohasd l grep -v grep<br>root<br>4056<br>11Feb19?<br>01 :54:34 /u01/app/12.1.0/grid/bin/ohasd.bin reboot<br>root<br>227151 O Feb19 ?<br>00:00:00 /bin/sh /etc/init.d/init.ohasd run</p>
<p>文件中的init.ohasd run部分启动了ohasd.bin后台进程:<br>$ ps -ef| grep ohasd | grep -V grep<br>root<br>4056 1 1 Feb19 ?<br>01:54:34 /u01/app/12.1 .0/grid/bin/ohasd.bin reboot<br>root<br>22715 1 0 Feb19 ?<br>00:00:00 /bin/sh /etc/init.d/init.ohasd run<br>一旦OHASD进程在第0级启动以后，在接下来的第1~4级，OHASD会直接或间接<br>地启动集群件的其他进程，以及该集群件管理的其他资源。以下内容解释了集群在这4个<br>等级中的启动顺序，如图2-3中所示。<br>第1级: OHASD直接派生4个代理进程。<br>●cssdmonitor: CSS监视器进程<br>●OHASD orarootagent:高可用性服务堆栈的Oracle root代理进程<br>●OHASDoraagent:高可用性服务堆栈的Oracle代理进程<br>●cssdagent: CSS的代理进程<br>第2级:在这个阶段，OHASD oraagent将派生5个进程。<br>●mDNSD: mDNS守护进程<br>●GIPCD: 网格进程间通信进程<br>●GPnPD: GPnP配置守护进程<br>●EVMD:事件监视器守护进程<br>●ASM:监测ASM实例的资源<br>然后，OHASD oraclerootagent 派生以下进程。<br>●CRSD: CRS守护进程<br>●CTSSD: CTSS守护进程<br>●Diskmon:磁盘监视器守护进程(Exadata存储服务器的存储)<br>●ACFS: (ASM集群文件系统)驱动程序<br>接下来，cssdagent 启动CSSD (CSS守护程序)进程。<br>第3级: CRSD派生两个CRSD代理进程: CRSD orarootagent和CRSD oracleagent。<br>第4级:在这个阶段，CRSD orarootagent负责启动以下资源。<br>●网络资源: 公共网络<br>●SCAN VIP<br>●节点VIP: 每个节点的虚拟IP地址<br>●ACFS 注册表<br>●GNSVIP:如果使用GNS选项，对应的GNS的虚拟IP地址<br>然后，CRSD orarootagent负责启动其他资源，包括如下项目。<br>●ASM资源:ASM实例资源<br>●<br>磁盘组:用来管理/监控ASM磁盘组。<br>数据库资源:用于监控和管理数据库和实例<br>●SCAN监听:SCAN监听的地址是SCAN的IP地址<br>●<br>扫描VIP: (单客户端访问名称)对应的虚拟IP地址<br>监听:监听的地址是节点的虚拟IP地址<br>●服务: 数据库服务<br>●ONS<br>eONS: ONS增强<br>●GSD:为了保持9i的向后兼容性<br>●GNS (可选):进行名称解析<br>CVU检查集群的健康状况，可以生成html报告<br>RACcheck执行各种重要的配置审计</p>
]]></content>
      <tags>
        <tag>oracle</tag>
        <tag>rac</tag>
      </tags>
  </entry>
  <entry>
    <title>strace</title>
    <url>/2021/05/19/strace/</url>
    <content><![CDATA[<p>1.常见选项的说明<br>Output format:<br>  -a column      alignment COLUMN for printing syscall results (default 40) //系统调用返回值的位置，默认是40<br>  -i             print instruction pointer at time of syscall //系统调用的入口指针<br>  -o file        send trace output to FILE instead of stderr //输出文件 可以使用 1&gt;filename  2&gt;&amp;1代替<br>  -q             suppress messages about attaching, detaching, etc. //抑制attaching 和detaching的消息，没有太弄明白<br>  -r             print relative timestamp //打印时间戳<br>  -s strsize     limit length of print strings to STRSIZE chars (default 32) //限制长度，实操上没有看到多大变化，没有太弄明白<br>  -t             print absolute timestamp // 打印时间戳，绝对时间，秒级别<br>  -tt            print absolute timestamp with usecs //时间ms级别<br>  -T             print time spent in each syscall //每个系统调用花费的时间，在每行的最后尖括号显示<br>  -x             print non-ascii strings in hex //以十六进制输出非标准字符串，read中的参数变化<br>  -xx            print all strings in hex //十六进制输出所有的字符串<br>  -y             print paths associated with file descriptor arguments //输出描述参数所关联的文件<br>  -yy            print ip:port pairs associated with socket file descriptors //输出socket文件描述匹配的ip:port套接字<br>Statistics:<br>  -c             count time, calls, and errors for each syscall and report summary //系统调用的时间，次数，错误，只打印系统调用产生的报告<br>  -C             like -c but also print regular output //比-c 打印多了strace正常的输出<br>  -O overhead    set overhead for tracing syscalls to OVERHEAD usecs //strace -c -O 3 ls,与-c一起使用，超过3微妙的系统调用报告<br>  -S sortby      sort syscall counts by: time, calls, name, nothing (default time) // 排序  strace -c -S calls  ls,根据调用次数进行排序<br>  -w             summarise syscall latency (default is system time) //与-c一起使用， strace -c  -w  ls,按照时间排序<br>Filtering:<br>  -e expr        a qualifying expression: option=[!]all or option=[!]val1[,val2]… //控制输出哪些函数 strace -e  connect,socket,poll ping <a href="http://www.baidu.com/">www.baidu.com</a><br>     options:    trace, abbrev, verbose, raw, signal, read, write<br>  -P path        trace accesses to path //跟踪某一路径，不太明白<br>Tracing:<br>  -b execve      detach on execve syscall //不太明白<br>  -D             run tracer process as a detached grandchild, not as parent<br>  -f             follow forks<br>  -ff            follow forks with output into separate files //跟踪创建进程输出到不同的文件，不太明白作用<br>  -I interruptible<br>     1:          no signals are blocked<br>     2:          fatal signals are blocked while decoding syscall (default)<br>     3:          fatal signals are always blocked (default if ‘-o FILE PROG’)<br>     4:          fatal signals and SIGTSTP (^Z) are always blocked<br>                 (useful to make ‘strace -o FILE PROG’ not stop on ^Z)<br>Startup:<br>  -E var         remove var from the environment for command<br>  -E var=val     put var=val in the environment for command<br>  -p pid         trace process with process id PID, may be repeated<br>  -u username    run command as username handling setuid and/or setgid<br>Miscellaneous:<br>  -d             enable debug output to stderr<br>  -v             verbose mode: print unabbreviated argv, stat, termios, etc. args<br>  -h             print help message<br>  -V             print version<br> 2.python使用strace实践</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;python3</span><br><span class="line">def test():</span><br><span class="line">    print(&quot;ouba&quot;)</span><br><span class="line">    import pdb</span><br><span class="line">    pdb.set_trace()</span><br><span class="line">    test2(30)</span><br><span class="line">    test2(10)</span><br><span class="line">    a&#x3D;Person(33)</span><br><span class="line">    b&#x3D;a</span><br><span class="line">    print(&quot;end&quot;)</span><br><span class="line">def test2(num):</span><br><span class="line">    for i in range(num):</span><br><span class="line">        print(&quot;num is %s&quot;%i)</span><br><span class="line">class Person(object):</span><br><span class="line">    def __init__(self, age):</span><br><span class="line">        self.age &#x3D; age</span><br><span class="line">        print(self.age)</span><br><span class="line">test()</span><br></pre></td></tr></table></figure>
<p>该脚本从第四行开始进入pdb调试,pdb help<br>Documented commands (type help <topic>):<br>========================================<br>EOF    bt         cont      enable  jump  pp       run      unt<br>a      c          continue  exit    l     q        s        until<br>alias  cl         d         h       list  quit     step     up<br>args   clear      debug     help    n     r        tbreak   w<br>b      commands   disable   ignore  next  restart  u        whatis<br>break  condition  down      j       p     return   unalias  where<br>Miscellaneous help topics:<br>==========================<br>exec  pdb<br>Undocumented commands:<br>======================<br>retval  rv<br>其中s是单步调试，n是块步进，list列出11行及当前代码行，p打印变量</p>
<p>3.常用的系统调用<br>系统调用函数分类：<br>进程管理<br>fork 创建一个新进程<br>clone 按指定条件创建子进程<br>execve 运行可执行文件<br>pause 进程将处于阻塞状态<br>wait 等待子进程终止<br>waitpid 等待指定子进程终止<br>文件和设备访问</p>
<p>open 打开文件<br>creat 创建新文件<br>close<br>read<br>pread 对文件随机读<br>pwrite 对文件随机写<br>poll I/O多路转换<br>truncate 截断文件</p>
<p>文件系统操作<br>access 确定文件的可存取性<br>chmod 确定文件的可存取性<br>chown 改变文件的属组或用户组<br>chroot 改变根目录<br>stat 获取文件状态信息<br>lstat 同stat<br>getdents 读取目录项<br>mkdir 创建目录<br>link 创建链接</p>
<p>内存管理<br>mmap 映射虚拟内存页<br>sync 将内存缓冲区数据写回硬盘<br>socket控制<br>socketcall socket系统调用<br>socket 建立socket<br>bind 绑定socket到端口<br>connect 连接远程主机<br>send 通过socket发送信息<br>sendto 发送UDP信息<br>sendmsg 参见send<br>listen 监听socket端口<br>select 对多路同步I/O进行轮询</p>
]]></content>
      <tags>
        <tag>operation</tag>
        <tag>strace</tag>
        <tag>troubleshooting</tag>
      </tags>
  </entry>
</search>
